<!DOCTYPE html><html lang="en" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="day-prompt" content="days ago"><meta name="hour-prompt" content="hours ago"><meta name="minute-prompt" content="minutes ago"><meta name="justnow-prompt" content="just now"><meta name="generator" content="Jekyll v4.2.1" /><meta property="og:title" content="Extreme Learning Machine: Thuật toán học nhanh cho mạng neuron truyền thẳng một lớp ẩn" /><meta name="author" content="tuanio" /><meta property="og:locale" content="en" /><meta name="description" content="Nội dung 1. Mạng neuron truyền thẳng một lớp ẩn 1.1 Định nghĩa 1.2 Bài toán học tham số 2. Thuật toán Extreme Learning Machine 3. Thực nghiệm thuật toán Extreme Learning Machine với hai bài toán: Regression và Classification 3.1 Kết quả 4. Tổng kết 5. Tham khảo" /><meta property="og:description" content="Nội dung 1. Mạng neuron truyền thẳng một lớp ẩn 1.1 Định nghĩa 1.2 Bài toán học tham số 2. Thuật toán Extreme Learning Machine 3. Thực nghiệm thuật toán Extreme Learning Machine với hai bài toán: Regression và Classification 3.1 Kết quả 4. Tổng kết 5. Tham khảo" /><link rel="canonical" href="https://tuanio.github.io//posts/elm/" /><meta property="og:url" content="https://tuanio.github.io//posts/elm/" /><meta property="og:site_name" content="tuanio" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2022-01-10T21:07:00+07:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Extreme Learning Machine: Thuật toán học nhanh cho mạng neuron truyền thẳng một lớp ẩn" /><meta name="twitter:site" content="@twitter_username" /><meta name="twitter:creator" content="@tuanio" /><meta name="google-site-verification" content="google_meta_tag_verification" /> <script type="application/ld+json"> {"author":{"@type":"Person","name":"tuanio"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://tuanio.github.io//posts/elm/"},"description":"Nội dung 1. Mạng neuron truyền thẳng một lớp ẩn 1.1 Định nghĩa 1.2 Bài toán học tham số 2. Thuật toán Extreme Learning Machine 3. Thực nghiệm thuật toán Extreme Learning Machine với hai bài toán: Regression và Classification 3.1 Kết quả 4. Tổng kết 5. Tham khảo","url":"https://tuanio.github.io//posts/elm/","@type":"BlogPosting","headline":"Extreme Learning Machine: Thuật toán học nhanh cho mạng neuron truyền thẳng một lớp ẩn","dateModified":"2022-08-28T19:56:09+07:00","datePublished":"2022-01-10T21:07:00+07:00","@context":"https://schema.org"}</script><title>Extreme Learning Machine: Thuật toán học nhanh cho mạng neuron truyền thẳng một lớp ẩn | tuanio</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="tuanio"><meta name="application-name" content="tuanio"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="https://cdn.jsdelivr.net"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script><body data-spy="scroll" data-target="#toc"><div id="sidebar" class="d-flex flex-column align-items-end" lang="en"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" alt="avatar" class="mx-auto"> <img src="https://deforani.sirv.com/Images/tuanio.github.io/avatar/avatar.jpg" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">tuanio</a></div><div class="site-subtitle font-italic">Một nơi để viết về những gì tôi đã học</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info-circle ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <a href="https://github.com/tuanio" aria-label="github" class="order-3" target="_blank" rel="noopener"> <i class="fab fa-github"></i> </a> <a href="https://www.facebook.com/tuanio1211/" aria-label="facebook" class="order-4" target="_blank" rel="noopener"> <i class="fab fa-facebook"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['nvatuan3','gmail.com'].join('@')" aria-label="email" class="order-5" > <i class="fas fa-envelope"></i> </a> <a href="https://www.linkedin.com/in/tuanio" aria-label="linkedin" class="order-6" target="_blank" rel="noopener"> <i class="fab fa-linkedin"></i> </a> <span class="icon-border order-2"></span> <span id="mode-toggle-wrapper" class="order-1"> <i class="mode-toggle fas fa-adjust"></i> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } var self = this; /* always follow the system prefers */ this.sysDarkPrefers.addListener(function() { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.updateMermaid(); }); } /* constructor() */ setDark() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_KEY); sessionStorage.removeItem(ModeToggle.MODE_KEY); } get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode == ModeToggle.DARK_MODE; } get isLightMode() { return this.mode == ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer) ) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } updateMermaid() { if (typeof mermaid !== "undefined") { let expectedTheme = (this.modeStatus === ModeToggle.DARK_MODE? "dark" : "default"); let config = { theme: expectedTheme }; /* re-render the SVG › <https://github.com/mermaid-js/mermaid/issues/311#issuecomment-332557344> */ $(".mermaid").each(function() { let svgCode = $(this).prev().children().html(); $(this).removeAttr("data-processed"); $(this).html(svgCode); }); mermaid.initialize(config); mermaid.init(undefined, ".mermaid"); } } flipMode() { if (this.hasMode) { if (this.isSysDarkPrefer) { if (this.isLightMode) { this.clearMode(); } else { this.setLight(); } } else { if (this.isDarkMode) { this.clearMode(); } else { this.setDark(); } } } else { if (this.isSysDarkPrefer) { this.setLight(); } else { this.setDark(); } } this.updateMermaid(); } /* flipMode() */ } /* ModeToggle */ let toggle = new ModeToggle(); $(".mode-toggle").click(function() { toggle.flipMode(); }); </script> </span></div></div><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Home </a> </span> <span>Extreme Learning Machine: Thuật toán học nhanh cho mạng neuron truyền thẳng một lớp ẩn</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="post-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>Extreme Learning Machine: Thuật toán học nhanh cho mạng neuron truyền thẳng một lớp ẩn</h1><div class="post-meta text-muted d-flex flex-column"><div> <span class="semi-bold"> tuanio </span> on <span class="timeago " data-toggle="tooltip" data-placement="bottom" title="Mon, Jan 10, 2022, 9:07 PM +0700" >Jan 10<i class="unloaded">2022-01-10T21:07:00+07:00</i> </span></div><div> <span> Updated <span class="timeago lastmod" data-toggle="tooltip" data-placement="bottom" title="Sun, Aug 28, 2022, 7:56 PM +0700" >Aug 28<i class="unloaded">2022-08-28T19:56:09+07:00</i> </span> </span> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="1981 words">11 min read</span></div></div><div class="post-content"><h3 id="nội-dung">Nội dung</h3><ul><li><a href="#-slfn">1. Mạng neuron truyền thẳng một lớp ẩn</a><ul><li><a href="#-dinh-nghia">1.1 Định nghĩa</a><li><a href="#-bai-toan-hoc-tham-so">1.2 Bài toán học tham số</a></ul><li><a href="#-elm">2. Thuật toán Extreme Learning Machine</a><li><a href="#-thuc-nghiem">3. Thực nghiệm thuật toán Extreme Learning Machine với hai bài toán: Regression và Classification</a><ul><li><a href="#-ket-qua">3.1 Kết quả</a></ul><li><a href="#-tong-ket">4. Tổng kết</a><li><a href="#-tham-khao">5. Tham khảo</a></ul><p><a name="-slfn"></a></p><h1 id="1-mạng-neuron-truyền-thẳng-một-lớp-ẩn">1. Mạng neuron truyền thẳng một lớp ẩn</h1><p><a name="-dinh-nghia"></a></p><h2 id="11-định-nghĩa">1.1 Định nghĩa</h2><p>Mạng neuron truyền thẳng một lớp ẩn (single hidden layer feedforward networks - <a href="https://en.wikipedia.org/wiki/Feedforward_neural_network" target="_blank">SLFN</a>) là một mạng neuron nhân tạo, mà các kết nối truyền thẳng từ đầu vào đến đầu ra. Đây là mô hình machine learning khá tốt được sử dụng trong rất nhiều lĩnh vực, SLFN có khả năng xấp xỉ một tập dữ liệu phức tạp trực tiếp từ dữ liệu đầu vào.</p><p>Cấu trúc của mạng neuron truyền thẳng một lớp ẩn bao gồm: 1 lớp đầu vào, 1 lớp ẩn và một lớp đầu ra. Hình 1 mô tả cấu trúc này.</p><p> <img data-proofer-ignore data-src="/assets/elm/SLFN.svg" alt="SLFN" /> <em>Hình 1: Cấu trúc của mạng neuron truyền thẳng một lớp ẩn</em></p><p>Giả sử ta có $N$ mẫu dữ liệu, mỗi mẫu là cặp $(\mathrm{x}_i, \mathrm{t}_i)$, trong đó:</p><ul><li>Vector \(\mathrm{x}_i = [x_{i1}, x_{i2}, \cdots, x_{in}] \in \mathrm{R}^n\) là dữ liệu đầu vào.<li>Vector \(\mathrm{t}_i = [x_{i1}, x_{i2}, \cdots, x_{im}] \in \mathrm{R}^m\) là dữ liệu đầu ra.</ul><p>Một cấu trúc của mạng neuron một lớp ẩn sẽ chứa những thành phần sau:</p><ul><li>Lớp ẩn có $\tilde{N}$ node.<li>Hàm kích hoạt (<a href="https://en.wikipedia.org/wiki/Activation_function" target="_blank">activation function</a>) cho lớp ẩn gọi là $g(x)$.<li>Ma trận trọng số dùng để kết nối dữ liệu đầu vào và lớp ẩn là \(\mathrm{W}_{nN} = [\mathrm{w}_1, \mathrm{w}_2, \cdots, \mathrm{w}_{\tilde{N}}]\), trong đó \(\mathrm{w}_i=[w_{i1}, w_{i2}, \cdots, w_{in}]^\intercal\).<li>Vector ngưỡng \(\mathrm{b}_i=[b_1, b_2, \cdots, b_{\tilde{N}}]\) để cộng thêm cho mỗi node ẩn.<li>Ma trận trọng số kết nối lớp ẩn với lớp đầu ra là \(\beta = [\beta_{1}, \beta_{2}, \cdots, \beta_{\tilde{N}}]\), với \(\beta_i=[\beta_{i1}, \beta_{i2}, \cdots, \beta_{im}]^\intercal\)</ul><p>Ta có thể viết các thành phần trên dưới dạng mô hình toán học như sau:</p>\[\sum_{i=1}^{\tilde{N}} \beta_i g_i(\mathrm{x}_j)=\sum_{i=1}^{\tilde{N}} \beta_i g_i(\mathrm{w}_i \cdot \mathrm{x}_j + b_i)=\mathrm{o}_j, j=1, \cdots, N\]<p>Mà vector $o_j$ chính là kết quả đầu ra của mạng neuron. Mục tiêu của chúng ta khi xây dựng mô hình là tìm được bộ trọng số $\mathrm{W}$, $\mathrm{b}$ và $\beta$ sao cho tối thiểu hóa sự khác nhau giữa đầu ra của mô hình $\mathrm{o}_j$ và đầu ra thực tế $\mathrm{t}_j$, cụ thể hơn là ta muốn sự sai khác bằng $0$!:</p>\[\sum_{i=1}^{\tilde{N}} ||\mathrm{o}_j - \mathrm{t}_j||=0\]<p><a name="-bai-toan-hoc-tham-so"></a></p><h2 id="12-bài-toán-học-tham-số">1.2 Bài toán học tham số</h2><p>Bài toán bây giờ là làm sao để học mạng neuron một lớp ẩn một cách tối ưu. Thông thường, ta có thể nghĩ đến thuật toán lan truyền ngược (back-propagation) kết hợp với gradient-descent để tối ưu bài toán qua các lần lặp. Nhưng thuật toán lan truyền ngược không hoàn hảo, tồn tại những nhược điểm của nó như là:</p><ol><li>Khi learning rate quá nhỏ, thuật toán hội tụ rất lâu. Tuy nhiên khi learning rate quá lớn, thuật toán sẽ không ổn định và trở nên phân kỳ.<li>Thuật toán dễ rơi vào local minima, mà chúng ta muốn thuật toán sẽ chạy xuống global minima, là điểm tối ưu nhất của bài toán (vì muốn sự sai khác bằng $0$ tuyệt đối).<li>Mạng neuron có thể bị quá khớp (overfit) hoặc không có khả năng tổng quát hóa (underfit) khi huấn luyện bằng back-propagation, vì vậy phải có một hàm chi phí, tiêu chí đánh giá, thời điểm dừng thích hợp và các siêu tham số khác phải tinh chỉnh.<li>Các dạng thuật toán học theo kiểu gradient rất tốn thời gian trong hầu hết các bài toán. Trong khi ta lại muốn giải một bài toán đơn giản nhanh chóng.</ol><p>Chung quy 4 nhược điểm trên, ta thấy back-propagation tốn thời gian và không phải lúc nào cũng sẽ tối ưu. Vì thế, ta cần một cách nhanh hơn và tối ưu hơn để giải bài toán ở trên, mà phần tiếp theo sẽ trình bày thuật toán <em>Extreme Learning Machine</em> để thay thế cho back-propagation trong ngữ cảnh bài toán này.</p><p><a name="-elm"></a></p><h1 id="2-thuật-toán-extreme-learning-machine">2. Thuật toán Extreme Learning Machine</h1><p>Trước tiên thì ta hãy nhìn lại vấn đề một chút. Vì chúng ta muốn sự sai khác tuyệt đối bằng $0$, nên sẽ tồn tại bộ trọng số $\mathrm{w}_i$, $\beta_i$ và $b_i$ để mà:</p>\[\sum_{i=1}^{\tilde{N}} \beta_i g_i(\mathrm{w}_i \cdot \mathrm{x}_j + b_i)=\mathrm{t}_j, j=1, \cdots, N\]<p>Ta có thể viết công thức trên dưới dạng ma trận như sau:</p>\[\mathrm{H}\beta = \mathrm{T}\]<p>Mà:</p>\[\mathrm{H}(\mathrm{w}_1, \cdots, \mathrm{w}_{\tilde{N}}, b_1, \cdots, b_{\tilde{N}}, \mathrm{x}_1, \cdots, \mathrm{x}_N)= \begin{aligned} \begin{bmatrix} g(\mathrm{w}_1\cdot \mathrm{x}_1 + b_1) &amp; \cdots &amp; g(\mathrm{w}_{\tilde{N}}\cdot \mathrm{x}_1 + b_{\tilde{N}}) \\ \vdots &amp; \cdots &amp; \vdots \\ g(\mathrm{w}_1\cdot \mathrm{x}_N + b_1) &amp; \cdots &amp; g(\mathrm{w}_{\tilde{N}}\cdot \mathrm{x}_N + b_{\tilde{N}}) \end{bmatrix} \end{aligned}_{N\times \tilde{N}}\] \[\beta = \begin{aligned} \begin{bmatrix} \beta_1^\intercal \\ \vdots \\ \beta_{\tilde{N}}^\intercal \end{bmatrix} \end{aligned}_{\tilde{N} \times m}\] \[T = \begin{aligned} \begin{bmatrix} t_1^\intercal \\ \vdots \\ t_{\tilde{N}}^\intercal \end{bmatrix} \end{aligned}_{N \times m}\]<p>Ta có thể thấy công thức \(\mathrm{H}\beta = \mathrm{T}\) giống hệt hệ phương trình với biến là $\beta$. Vì thế, ta có thể giải và tìm $\beta$ theo công thức:</p>\[\hat{\beta} = \mathrm{H}^\dagger\mathrm{T}\]<p>Trong đó, $\hat{\beta}$ là nghiệm $\beta$ tối ưu, kí hiệu $\dagger$ (dagger) đại diện cho phép nghịch đảo ma trận theo phương pháp Moore-Penrose, bạn đọc có thể tìm hiểu thêm ở <a href="https://en.wikipedia.org/wiki/Moore%E2%80%93Penrose_inverse" target="_blank">đây</a>. Lúc này, nghiệm của bài toán sẽ là duy nhất, vì nghiệm của phương pháp nghịch đảo ma trận Moore-Penrose là duy nhất.</p><p>Vấn đề là còn lại $\mathrm{W}$ và $\mathrm{b}$ chưa có lời giải. Nhưng thực ra, theo nghiên cứu <a href="#-reference-1">[1]</a>, tác giả Guang-Bin Huang và đồng nghiệp đã chứng minh một cách chặt chẽ rằng: Bài toán <strong>luôn luôn có nghiệm</strong> mặc dù $\mathrm{W}$ và $\mathrm{b}$ có thể được chọn ngẫu nhiên như thế nào đi chăng nữa. Nên vấn đề của $\mathrm{W}$ và $\mathrm{b}$ đã được giải quyết.</p><p>Vì thế, nhóm tác giả đã trình bày thuật toán Extreme Learning Machine (có thể gọi là ELM) gồm các bước sau:</p><ul><li><em>Bước 1</em>: Ngẫu nhiên chọn giá trị cho $\mathrm{w}_i$ và $\mathrm{b}_i$ với $i=1,\cdots, \tilde{N}$.<li><em>Bước 2</em>: Tính giá trị của ma trận trọng số kết nối đầu vào và lớp ẩn $H$.<li><em>Bước 3</em>: Tính giá trị của ma trận trọng số kết nối lớp ẩn và đầu ra $\beta$.</ul><p>Điểm đặc biệt của thuật toán này là học rất nhanh, do đây là thuật toán huấn luyện không lặp, cải thiện thời gian rất nhiều, không giống như phương pháp gradient-descent, là thuật toán tối ưu lặp.</p><p>Đối với các bài toán khác nhau, sẽ có cách chọn $g(x)$ khác nhau. Có thể chọn giữa các hàm như: linear activation, relu, sigmoid, softmax, tanh, v.v.</p><p>Trong bài toán Regression, đầu ra có thể là hàm tuyến tính (linear activation), nghĩa là không cần hàm kích hoạt. Còn trong bài toán Classification, hàm kích hoạt đầu ra có thể dùng là hàm sigmoid đối với bài toán phân lớp nhị phân, hoặc softmax nếu là phân lớp đa lớp. Lúc này, ký hiệu hàm kích hoạt đầu ra là \(\sigma(\mathrm{o}_j)\), trong đó $\sigma$ có thể là các hàm linear activation, sigmoid hoặc softmax như đã đề cập.</p><p><a name="-thuc-nghiem"></a></p><h1 id="3-thực-nghiệm-thuật-toán-extreme-learning-machine-với-hai-bài-toán-regression-và-classification">3. Thực nghiệm thuật toán Extreme Learning Machine với hai bài toán: Regression và Classification</h1><p>Do thuật toán ELM thực chất cũng khá đơn giản, nên ta có thể thực hiện trực tiếp với Python và thư viện Numpy. Dưới đây là đoạn code tham khảo về việc hiện thực thuật toán ELM cho hai bài toán Regression và Classification, với lớp <code class="language-plaintext highlighter-rouge">ELMRegressor</code> đại diện cho bài toán Regression, và lớp <code class="language-plaintext highlighter-rouge">ELMClassifier</code> đại diện cho bài toán Classification.</p><p>Gọi $X$ là ma trận dữ liệu đầu vào, $y$ là vector dữ liệu đầu ra, lúc này $y$ có thể thay thế cho $T$ đối với mạng neuron một lớp ẩn.</p><div class="language-python highlighter-rouge"><div class="code-header"> <span text-data=" Python "><i class="fa-fw fas fa-code small"></i></span> <button aria-label="copy" title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
</pre><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">OneHotEncoder</span>
<span class="kn">from</span> <span class="nn">scipy.special</span> <span class="kn">import</span> <span class="n">softmax</span>
<span class="kn">from</span> <span class="nn">utils</span> <span class="kn">import</span> <span class="n">relu</span><span class="p">,</span> <span class="n">sigmoid</span><span class="p">,</span> <span class="n">linear</span>

<span class="k">class</span> <span class="nc">ELMBase</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_hiddens</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">linear</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">n_hiddens</span> <span class="o">=</span> <span class="n">n_hiddens</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">rs</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">RandomState</span><span class="p">(</span><span class="n">random_state</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">activation</span>
    
    
<span class="k">class</span> <span class="nc">ELMRegressor</span><span class="p">(</span><span class="n">ELMBase</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_hiddens</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">12</span><span class="p">):</span>
        <span class="n">ELMBase</span><span class="p">.</span><span class="n">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_hiddens</span><span class="p">,</span> <span class="n">random_state</span><span class="p">,</span> <span class="n">linear</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">W</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">rs</span><span class="p">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">X</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="p">.</span><span class="n">n_hiddens</span><span class="p">))</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">b</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">rs</span><span class="p">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">n_hiddens</span><span class="p">))</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        
        <span class="n">H</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">activation</span><span class="p">(</span><span class="n">X</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">W</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="p">.</span><span class="n">b</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">Beta</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="n">pinv</span><span class="p">(</span><span class="n">H</span><span class="p">).</span><span class="n">dot</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span>
    
    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="n">H</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">activation</span><span class="p">(</span><span class="n">X</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">W</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="p">.</span><span class="n">b</span><span class="p">)</span>
        <span class="n">dot_product</span> <span class="o">=</span> <span class="n">H</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">Beta</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">dot_product</span>
    
    
<span class="k">class</span> <span class="nc">ELMClassifier</span><span class="p">(</span><span class="n">ELMBase</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_hiddens</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">12</span><span class="p">):</span>
        <span class="n">ELMBase</span><span class="p">.</span><span class="n">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_hiddens</span><span class="p">,</span> <span class="n">random_state</span><span class="p">,</span> <span class="n">relu</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">output_activation</span> <span class="o">=</span> <span class="n">softmax</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">OneHotEncoder</span><span class="p">()</span>
        
    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">W</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">rs</span><span class="p">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">X</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="p">.</span><span class="n">n_hiddens</span><span class="p">))</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">b</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">rs</span><span class="p">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">n_hiddens</span><span class="p">))</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">encoder</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">y</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)).</span><span class="n">toarray</span><span class="p">()</span>
        
        <span class="n">H</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">activation</span><span class="p">(</span><span class="n">X</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">W</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="p">.</span><span class="n">b</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">Beta</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="n">pinv</span><span class="p">(</span><span class="n">H</span><span class="p">).</span><span class="n">dot</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">predict_proba</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="n">H</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">activation</span><span class="p">(</span><span class="n">X</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">W</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="p">.</span><span class="n">b</span><span class="p">)</span>
        <span class="n">dot_product</span> <span class="o">=</span> <span class="n">H</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">Beta</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">output_activation</span><span class="p">(</span><span class="n">dot_product</span><span class="p">)</span>
</pre></table></code></div></div><p>Sau khi đã hiện thực được thuật toán, ta có thể đi so sánh kết quả (thời gian và độ chính xác) với các thuật toán khác, trong bài viết này, tôi sử dụng các dạng mô hình tuyến tính (linear model) như Ridge và Logistic Regression, mô hình dạng Support Vector Machine (SVM), mô hình K-Nearest Neighbors (KNN), dạng mô hình cây Decision Tree, mô hình cây kết hợp Random Forest và mô hình Perceptron 1 lớp ẩn (được huấn luyện bằng back-propagation).</p><p>Kết quả sẽ được so sánh trên hai bộ dữ liệu: Boston Housing cho bài toán và MNIST cho bài toán . Mà thang đo cho bài toán sẽ là Root Mean Square Error (căn bậc hai bình phương trung bình sai số) và accuracy (độ chính xác) đối với bài toán .</p><p><a name="-ket-qua"></a></p><h2 id="31-kết-quả-so-sánh">3.1 Kết quả so sánh</h2><p>Mạng neuron một lớp ẩn và Perceptron sẽ có số lượng node ở lớp ẩn là $500$, các tham số của các mô hình khác đều được giữ mặc định.</p><p><strong>Kết quả trên bộ dữ liệu Boston Housing</strong></p><div class="table-wrapper"><table><thead><tr><th>Thuật toán<th>Loại<th style="text-align: center">Thời gian huấn luyện (mili giây)<th style="text-align: center">RMSE trên tập huấn luyện<th style="text-align: center">RMSE trên tập kiểm thử<tbody><tr><td>ELM<td>Neural Network<td style="text-align: center">54.62<td style="text-align: center">4.69<td style="text-align: center">4.82<tr><td>Ridge<td>Linear Model<td style="text-align: center">2.66<td style="text-align: center">4.72<td style="text-align: center">4.75<tr><td>SVR<td>Support Vector Machine<td style="text-align: center">26.32<td style="text-align: center">8.25<td style="text-align: center">8.15<tr><td>K-Nearest Neighbors<td>Nearest Neighbors<td style="text-align: center">1.97<td style="text-align: center">4.98<td style="text-align: center">6.08<tr><td>Decision Tree<td>Tree-based<td style="text-align: center">7.2<td style="text-align: center">0<td style="text-align: center">5.1<tr><td>Random Forest<td>Tree-based Ensemble<td style="text-align: center">293.13<td style="text-align: center">1.19<td style="text-align: center">3.8<tr><td>Perceptron (Back-propagation)<td>Neural Network<td style="text-align: center">237.5<td style="text-align: center">6.94<td style="text-align: center">7.43</table></div><p><strong>Kết quả trên bộ dữ liệu MNIST</strong></p><div class="table-wrapper"><table><thead><tr><th>Thuật toán<th>Loại<th style="text-align: center">Thời gian huấn luyện (mili giây)<th style="text-align: center">Độ chính xác trên tập huấn luyện (%)<th style="text-align: center">Độ chính xác trên tập kiểm thử (%)<tbody><tr><td>ELM<td>Neural Network<td style="text-align: center">4754.13<td style="text-align: center">91.94<td style="text-align: center">92.22<tr><td>Logistic<td>Linear Model<td style="text-align: center">21112.03<td style="text-align: center">93.39<td style="text-align: center">92.55<tr><td>SVC<td>Support Vector Machine<td style="text-align: center">280275.89<td style="text-align: center">98.99<td style="text-align: center">97.92<tr><td>K-Nearest Neighbors<td>Nearest Neighbors<td style="text-align: center">5.07<td style="text-align: center">98.19<td style="text-align: center">96.88<tr><td>Decision Tree<td>Tree-based<td style="text-align: center">17913.2<td style="text-align: center">100.0<td style="text-align: center">87.68<tr><td>Random Forest<td>Tree-based Ensemble<td style="text-align: center">37244.7<td style="text-align: center">100.0<td style="text-align: center">96.95<tr><td>Perceptron (Back-propagation)<td>Neural Network<td style="text-align: center">379703.05<td style="text-align: center">99.73<td style="text-align: center">97.85</table></div><p>Bạn đọc có thể tham khảo toàn bộ code hiện thực trong bài viết này ở <a href="https://github.com/tuanio/elm-implementation" target="_blank">đây</a>.</p><p><a name="-tong-ket"></a></p><h1 id="4-tổng-kết">4. Tổng kết</h1><p>Qua bài viết này, tôi đã trình bày về cấu trúc của mô hình mạng neuron truyển thẳng một lớp ẩn (SLFN) và vấn đề bất cập trong việc tìm các trọng số của mô hình với thuật toán back-propagation. Từ đó nêu lên thuật toán Extreme Learning Machine giúp giải quyết vấn đề học một cách nhanh và tối ưu. Kết quả thực nghiệm trong phần 3.1 cho thấy rằng tốc độ học của Extreme Learning Machine nhanh hơn hẳn so với back-propagation (mô hình Perceptron), tuy nhiên khi so sánh với các thuật toán đơn giản hơn nhiều như K-Nearest Neighbors thì chưa nhanh bằng, dù gì thì ELM cũng là một mạng neuron nên cấu trúc sẽ phức tạp hơn.</p><p><a name="-tham-khao"></a></p><h1 id="5-tham-khảo">5. Tham khảo</h1><p><a name="-reference-1"></a> [1] Guang-Bin Huang, Qin-Yu Zhu, Chee-Kheong Siew, Extreme learning machine: Theory and applications, 2006. <a href="https://doi.org/10.1016/j.neucom.2005.12.126" target="_blank">https://doi.org/10.1016/j.neucom.2005.12.126</a>.</p></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/knowledge/'>knowledge</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/machine-learning/" class="post-tag no-text-decoration" >machine learning</a> <a href="/tags/elm/" class="post-tag no-text-decoration" >elm</a> <a href="/tags/feedforward-neural-network/" class="post-tag no-text-decoration" >feedforward neural network</a> <a href="/tags/mnist-dataset/" class="post-tag no-text-decoration" >mnist dataset</a> <a href="/tags/boston-housing-dataset/" class="post-tag no-text-decoration" >boston housing dataset</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=Extreme Learning Machine: Thuật toán học nhanh cho mạng neuron truyền thẳng một lớp ẩn - tuanio&url=https://tuanio.github.io//posts/elm/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=Extreme Learning Machine: Thuật toán học nhanh cho mạng neuron truyền thẳng một lớp ẩn - tuanio&u=https://tuanio.github.io//posts/elm/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=Extreme Learning Machine: Thuật toán học nhanh cho mạng neuron truyền thẳng một lớp ẩn - tuanio&url=https://tuanio.github.io//posts/elm/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="Copy link" title-succeed="Link copied successfully!"> </i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-lastmod" class="post"> <span>Recent Update</span><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/autorec/">AutoRec: Autoencoder dành cho Collaborative Filtering</a><li><a href="/posts/source-nlp/">Nguồn tài liệu để học NLP</a><li><a href="/posts/markov-chain-va-bai-toan-sang-nay-an-gi/">Markov Chain và bài toán 'Sáng nay ăn gì'</a><li><a href="/posts/minh-da-hoc-duoc-ghi-trong-nam-nay/">Mình đã học được gì trong năm nay?</a><li><a href="/posts/hidden-markov-model-and-sentiment-analysis/">Mô hình Markov ẩn và bài toán phân tích cảm xúc văn bản</a></ul></div><div id="access-tags"> <span>Trending Tags</span><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/machine-learning/">machine learning</a> <a class="post-tag" href="/tags/autoencoder/">autoencoder</a> <a class="post-tag" href="/tags/feedforward-neural-network/">feedforward neural network</a> <a class="post-tag" href="/tags/markov-process/">markov process</a> <a class="post-tag" href="/tags/nlp/">nlp</a> <a class="post-tag" href="/tags/probability/">probability</a> <a class="post-tag" href="/tags/supervised-learning/">supervised learning</a> <a class="post-tag" href="/tags/alexnet/">alexnet</a> <a class="post-tag" href="/tags/anomaly-detection/">anomaly detection</a> <a class="post-tag" href="/tags/audio-classification/">audio classification</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"> <span class="pl-3 pt-2 mb-2">Contents</span><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/autoencoder/"><div class="card-body"> <span class="timeago small" >Jan 16<i class="unloaded">2022-01-16T15:33:00+07:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Autoencoder và bài toán phát hiện bất thường trong an ninh mạng</h3><div class="text-muted small"><p> Nội dung 1. Giới thiệu Autoencoder 2. Bài toán phát hiện bất thường trong an ninh mạng 3. Thực nghiệm Autoencoder với bộ dữ liệu NSL-KDD 3.1 Giới thiệu bộ dữ liệu NSL-KDD 3....</p></div></div></a></div><div class="card"> <a href="/posts/source-nlp/"><div class="card-body"> <span class="timeago small" >Dec 23, 2021<i class="unloaded">2021-12-23T15:11:00+07:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Nguồn tài liệu để học NLP</h3><div class="text-muted small"><p> Bài viết này mang tính chất lưu trữ và chia sẻ. Những nguồn khi mới bắt đầu How to get started in nlp - medium Dữ liệu nlp-datasets - github Sách Deep Learning for NLP and Speech R...</p></div></div></a></div><div class="card"> <a href="/posts/markov-chain-va-bai-toan-sang-nay-an-gi/"><div class="card-body"> <span class="timeago small" >Dec 26, 2021<i class="unloaded">2021-12-26T21:35:00+07:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Markov Chain và bài toán 'Sáng nay ăn gì'</h3><div class="text-muted small"><p> Nội dung 1. Định nghĩa Markov chain 2. Bài toán “sáng nay ăn gì” 3. Tổng kết Trong bài viết này, chúng ta sẽ đi qua sơ lược về định nghĩa của Markov chain, từ đó hiểu thêm về Markov chain ...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/hidden-markov-model-and-sentiment-analysis/" class="btn btn-outline-primary" prompt="Older"><p>Mô hình Markov ẩn và bài toán phân tích cảm xúc văn bản</p></a> <a href="/posts/autoencoder/" class="btn btn-outline-primary" prompt="Newer"><p>Autoencoder và bài toán phát hiện bất thường trong an ninh mạng</p></a></div></div></div></div><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center"><div class="footer-left"><p class="mb-0"> © 2022 <a href="https://github.com/tuanio">Nguyễn Văn Anh Tuấn</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><h4 class="text-muted mb-4">Trending Tags</h4><a class="post-tag" href="/tags/machine-learning/">machine learning</a> <a class="post-tag" href="/tags/autoencoder/">autoencoder</a> <a class="post-tag" href="/tags/feedforward-neural-network/">feedforward neural network</a> <a class="post-tag" href="/tags/markov-process/">markov process</a> <a class="post-tag" href="/tags/nlp/">nlp</a> <a class="post-tag" href="/tags/probability/">probability</a> <a class="post-tag" href="/tags/supervised-learning/">supervised learning</a> <a class="post-tag" href="/tags/alexnet/">alexnet</a> <a class="post-tag" href="/tags/anomaly-detection/">anomaly detection</a> <a class="post-tag" href="/tags/audio-classification/">audio classification</a></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/lozad/dist/lozad.min.js,npm/magnific-popup@1/dist/jquery.magnific-popup.min.js,npm/clipboard@2/dist/clipboard.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script> /* see: <https://docs.mathjax.org/en/latest/options/input/tex.html#tex-options> */ MathJax = { tex: { inlineMath: [ /* start/end delimiter pairs for in-line math */ ['$','$'], ['\\(','\\)'] ], displayMath: [ /* start/end delimiter pairs for display math */ ['$$', '$$'], ['\\[', '\\]'] ] } }; </script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"> </script> <script src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.16.1,npm/bootstrap@4/dist/js/bootstrap.min.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id=G-ZJYTV5L278"></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'G-ZJYTV5L278'); }); </script>
