---
title: "Extreme Learning Machine: Thuật toán học nhanh cho mạng neuron truyền thẳng một lớp ẩn"
date: 2022-1-10 21:07:00 +/-0084
categories: [knowledge]
tags: [machine learning, elm, feedforward neural network, mnist dataset, boston housing dataset]
toc: true
comments: true
published: true
math: true
---

### Nội dung
- [1. Mạng neuron truyền thẳng một lớp ẩn](#-slfn)
    - [1.1 Định nghĩa](#-dinh-nghia)
    - [1.2 Bài toán học tham số](#-bai-toan-hoc-tham-so)
- [2. Thuật toán Extreme Learning Machine](#-elm)
- [3. Thực nghiệm thuật toán Extreme Learning Machine với hai bài toán: Regression và Classification](#-thuc-nghiem)
    - [3.1 Kết quả](#-ket-qua)
- [4. Tổng kết](#-tong-ket)
- [5. Tham khảo](#-tham-khao)

<a name="-slfn"></a>
# 1. Mạng neuron truyền thẳng một lớp ẩn

<a name="-dinh-nghia"></a>
## 1.1 Định nghĩa
Mạng neuron truyền thẳng một lớp ẩn (single hidden layer feedforward networks - <a href="https://en.wikipedia.org/wiki/Feedforward_neural_network" target="_blank">SLFN</a>) là một mạng neuron nhân tạo, mà các kết nối truyền thẳng từ đầu vào đến đầu ra. Đây là mô hình machine learning khá tốt được sử dụng trong rất nhiều lĩnh vực, SLFN có khả năng xấp xỉ một tập dữ liệu phức tạp trực tiếp từ dữ liệu đầu vào.

Cấu trúc của mạng neuron truyền thẳng một lớp ẩn bao gồm: 1 lớp đầu vào, 1 lớp ẩn và một lớp đầu ra. Hình 1 mô tả cấu trúc này.

<p>
    <img src="/assets/elm/SLFN.svg" alt="SLFN"/>
    <em>Hình 1: Cấu trúc của mạng neuron truyền thẳng một lớp ẩn</em>
</p>

Giả sử ta có $N$ mẫu dữ liệu, mỗi mẫu là cặp $(\mathrm{x}_i, \mathrm{t}_i)$, trong đó:
- Vector $$\mathrm{x}_i = [x_{i1}, x_{i2}, \cdots, x_{in}] \in \mathrm{R}^n$$ là dữ liệu đầu vào.
- Vector $$\mathrm{t}_i = [x_{i1}, x_{i2}, \cdots, x_{im}] \in \mathrm{R}^m$$ là dữ liệu đầu ra.

Một cấu trúc của mạng neuron một lớp ẩn sẽ chứa những thành phần sau:
- Lớp ẩn có $\tilde{N}$ node.
- Hàm kích hoạt (<a href="https://en.wikipedia.org/wiki/Activation_function" target="_blank">activation function</a>) cho lớp ẩn gọi là $g(x)$.
- Ma trận trọng số dùng để kết nối dữ liệu đầu vào và lớp ẩn là $$\mathrm{W}_{nN} = [\mathrm{w}_1, \mathrm{w}_2, \cdots, \mathrm{w}_{\tilde{N}}]$$, trong đó $$\mathrm{w}_i=[w_{i1}, w_{i2}, \cdots, w_{in}]^\intercal$$.
- Vector ngưỡng $$\mathrm{b}_i=[b_1, b_2, \cdots, b_{\tilde{N}}]$$ để cộng thêm cho mỗi node ẩn.
- Ma trận trọng số kết nối lớp ẩn với lớp đầu ra là $$\beta = [\beta_{1}, \beta_{2}, \cdots, \beta_{\tilde{N}}]$$, với $$\beta_i=[\beta_{i1}, \beta_{i2}, \cdots, \beta_{im}]^\intercal$$


Ta có thể viết các thành phần trên dưới dạng mô hình toán học như sau:

$$\sum_{i=1}^{\tilde{N}} \beta_i g_i(\mathrm{x}_j)=\sum_{i=1}^{\tilde{N}} \beta_i g_i(\mathrm{w}_i \cdot \mathrm{x}_j + b_i)=\mathrm{o}_j, j=1, \cdots, N$$

Mà vector $o_j$ chính là kết quả đầu ra của mạng neuron. Mục tiêu của chúng ta khi xây dựng mô hình là tìm được bộ trọng số $\mathrm{W}$, $\mathrm{b}$ và $\beta$ sao cho tối thiểu hóa sự khác nhau giữa đầu ra của mô hình $\mathrm{o}_j$ và đầu ra thực tế $\mathrm{t}_j$, cụ thể hơn là ta muốn sự sai khác bằng $0$!:

$$\sum_{i=1}^{\tilde{N}} ||\mathrm{o}_j - \mathrm{t}_j||=0$$

<a name="-bai-toan-hoc-tham-so"></a>
## 1.2 Bài toán học tham số

Bài toán bây giờ là làm sao để học mạng neuron một lớp ẩn một cách tối ưu. Thông thường, ta có thể nghĩ đến thuật toán lan truyền ngược (back-propagation) kết hợp với gradient-descent để tối ưu bài toán qua các lần lặp. Nhưng thuật toán lan truyền ngược không hoàn hảo, tồn tại những nhược điểm của nó như là:
1. Khi learning rate quá nhỏ, thuật toán hội tụ rất lâu. Tuy nhiên khi learning rate quá lớn, thuật toán sẽ không ổn định và trở nên phân kỳ.
2. Thuật toán dễ rơi vào local minima, mà chúng ta muốn thuật toán sẽ chạy xuống global minima, là điểm tối ưu nhất của bài toán (vì muốn sự sai khác bằng $0$ tuyệt đối).
3. Mạng neuron có thể bị quá khớp (overfit) hoặc không có khả năng tổng quát hóa (underfit) khi huấn luyện bằng back-propagation, vì vậy phải có một hàm chi phí, tiêu chí đánh giá, thời điểm dừng thích hợp và các siêu tham số khác phải tinh chỉnh. 
4. Các dạng thuật toán học theo kiểu gradient rất tốn thời gian trong hầu hết các bài toán. Trong khi ta lại muốn giải một bài toán đơn giản nhanh chóng.

Chung quy 4 nhược điểm trên, ta thấy back-propagation tốn thời gian và không phải lúc nào cũng sẽ tối ưu. Vì thế, ta cần một cách nhanh hơn và tối ưu hơn để giải bài toán ở trên, mà phần tiếp theo sẽ trình bày thuật toán *Extreme Learning Machine* để thay thế cho back-propagation trong ngữ cảnh bài toán này.

<a name="-elm"></a>
# 2. Thuật toán Extreme Learning Machine

Trước tiên thì ta hãy nhìn lại vấn đề một chút. Vì chúng ta muốn sự sai khác tuyệt đối bằng $0$, nên sẽ tồn tại bộ trọng số $\mathrm{w}_i$, $\beta_i$ và $b_i$ để mà:

$$\sum_{i=1}^{\tilde{N}} \beta_i g_i(\mathrm{w}_i \cdot \mathrm{x}_j + b_i)=\mathrm{t}_j, j=1, \cdots, N$$

Ta có thể viết công thức trên dưới dạng ma trận như sau:

$$\mathrm{H}\beta = \mathrm{T}$$

Mà:

$$\mathrm{H}(\mathrm{w}_1, \cdots, \mathrm{w}_{\tilde{N}}, b_1, \cdots, b_{\tilde{N}}, \mathrm{x}_1, \cdots, \mathrm{x}_N)=
\begin{aligned}
\begin{bmatrix}
g(\mathrm{w}_1\cdot \mathrm{x}_1 + b_1) & \cdots & g(\mathrm{w}_{\tilde{N}}\cdot \mathrm{x}_1 + b_{\tilde{N}}) \\
\vdots & \cdots & \vdots \\
g(\mathrm{w}_1\cdot \mathrm{x}_N + b_1) & \cdots & g(\mathrm{w}_{\tilde{N}}\cdot \mathrm{x}_N + b_{\tilde{N}})
\end{bmatrix}
\end{aligned}_{N\times \tilde{N}}$$

$$\beta =
\begin{aligned}
\begin{bmatrix}
\beta_1^\intercal \\
\vdots \\
\beta_{\tilde{N}}^\intercal
\end{bmatrix}
\end{aligned}_{\tilde{N} \times m}$$

$$T =
\begin{aligned}
\begin{bmatrix}
t_1^\intercal \\
\vdots \\
t_{\tilde{N}}^\intercal
\end{bmatrix}
\end{aligned}_{N \times m}$$

Ta có thể thấy công thức $$\mathrm{H}\beta = \mathrm{T}$$ giống hệt hệ phương trình với biến là $\beta$. Vì thế, ta có thể giải và tìm $\beta$ theo công thức:

$$\hat{\beta} = \mathrm{H}^\dagger\mathrm{T}$$

Trong đó, $\hat{\beta}$ là nghiệm $\beta$ tối ưu, kí hiệu $\dagger$ (dagger) đại diện cho phép nghịch đảo ma trận theo phương pháp Moore-Penrose, bạn đọc có thể tìm hiểu thêm ở <a href="https://en.wikipedia.org/wiki/Moore%E2%80%93Penrose_inverse" target="_blank">đây</a>. Lúc này, nghiệm của bài toán sẽ là duy nhất, vì nghiệm của phương pháp nghịch đảo ma trận Moore-Penrose là duy nhất.

Vấn đề là còn lại $\mathrm{W}$ và $\mathrm{b}$ chưa có lời giải. Nhưng thực ra, theo nghiên cứu [[1]](#-reference-1), tác giả Guang-Bin Huang và đồng nghiệp đã chứng minh một cách chặt chẽ rằng: Bài toán **luôn luôn có nghiệm** mặc dù $\mathrm{W}$ và $\mathrm{b}$ có thể được chọn ngẫu nhiên như thế nào đi chăng nữa. Nên vấn đề của $\mathrm{W}$ và $\mathrm{b}$ đã được giải quyết.

Vì thế, nhóm tác giả đã trình bày thuật toán Extreme Learning Machine (có thể gọi là ELM) gồm các bước sau:
- *Bước 1*: Ngẫu nhiên chọn giá trị cho $\mathrm{w}_i$ và $\mathrm{b}_i$ với $i=1,\cdots, \tilde{N}$.
- *Bước 2*: Tính giá trị của ma trận trọng số kết nối đầu vào và lớp ẩn $H$.
- *Bước 3*: Tính giá trị của ma trận trọng số kết nối lớp ẩn và đầu ra $\beta$.

Điểm đặc biệt của thuật toán này là học rất nhanh, do đây là thuật toán huấn luyện không lặp, cải thiện thời gian rất nhiều, không giống như phương pháp gradient-descent, là thuật toán tối ưu lặp.

Đối với các bài toán khác nhau, sẽ có cách chọn $g(x)$ khác nhau. Có thể chọn giữa các hàm như: linear activation, relu, sigmoid, softmax, tanh, v.v.

Trong bài toán Regression, đầu ra có thể là hàm tuyến tính (linear activation), nghĩa là không cần hàm kích hoạt. Còn trong bài toán Classification, hàm kích hoạt đầu ra có thể dùng là hàm sigmoid đối với bài toán phân lớp nhị phân, hoặc softmax nếu là phân lớp đa lớp. Lúc này, ký hiệu hàm kích hoạt đầu ra là $$\sigma(\mathrm{o}_j)$$, trong đó $\sigma$ có thể là các hàm linear activation, sigmoid hoặc softmax như đã đề cập.

<a name="-thuc-nghiem"></a>
# 3. Thực nghiệm thuật toán Extreme Learning Machine với hai bài toán: Regression và Classification

Do thuật toán ELM thực chất cũng khá đơn giản, nên ta có thể thực hiện trực tiếp với Python và thư viện Numpy. Dưới đây là đoạn code tham khảo về việc hiện thực thuật toán ELM cho hai bài toán Regression và Classification, với lớp `ELMRegressor` đại diện cho bài toán Regression, và lớp `ELMClassifier` đại diện cho bài toán Classification.

Gọi $X$ là ma trận dữ liệu đầu vào, $y$ là vector dữ liệu đầu ra, lúc này $y$ có thể thay thế cho $T$ đối với mạng neuron một lớp ẩn.

````python
import numpy as np
from sklearn.preprocessing import OneHotEncoder
from scipy.special import softmax
from utils import relu, sigmoid, linear

class ELMBase:
    def __init__(self, n_hiddens=128, random_state=12, activation=linear):
        self.n_hiddens = n_hiddens
        self.rs = np.random.RandomState(random_state)
        self.activation = activation
    
    
class ELMRegressor(ELMBase):
    def __init__(self, n_hiddens=128, random_state=12):
        ELMBase.__init__(self, n_hiddens, random_state, linear)
        
    def fit(self, X, y):
        self.W = self.rs.normal(size=(X.shape[1], self.n_hiddens))
        self.b = self.rs.normal(size=(self.n_hiddens))
        y = y.reshape(-1, 1)
        
        H = self.activation(X.dot(self.W) + self.b)
        self.Beta = np.linalg.pinv(H).dot(y)
        return self
    
    def predict(self, X):
        H = self.activation(X.dot(self.W) + self.b)
        dot_product = H.dot(self.Beta)
        return dot_product
    
    
class ELMClassifier(ELMBase):
    def __init__(self, n_hiddens=128, random_state=12):
        ELMBase.__init__(self, n_hiddens, random_state, relu)
        self.output_activation = softmax
        self.encoder = OneHotEncoder()
        
    def fit(self, X, y):
        self.W = self.rs.normal(size=(X.shape[1], self.n_hiddens))
        self.b = self.rs.normal(size=(self.n_hiddens))
        y = self.encoder.fit_transform(y.reshape(-1, 1)).toarray()
        
        H = self.activation(X.dot(self.W) + self.b)
        self.Beta = np.linalg.pinv(H).dot(y)
        return self

    def predict(self, X):
        return np.argmax(self.predict_proba(X), axis=1)
    
    def predict_proba(self, X):
        H = self.activation(X.dot(self.W) + self.b)
        dot_product = H.dot(self.Beta)
        return self.output_activation(dot_product)
````

Sau khi đã hiện thực được thuật toán, ta có thể đi so sánh kết quả (thời gian và độ chính xác) với các thuật toán khác, trong bài viết này, tôi sử dụng các dạng mô hình tuyến tính (linear model) như Ridge và Logistic Regression, mô hình dạng Support Vector Machine (SVM), mô hình K-Nearest Neighbors (KNN), dạng mô hình cây Decision Tree, mô hình cây kết hợp Random Forest và mô hình Perceptron 1 lớp ẩn (được huấn luyện bằng back-propagation). 

Kết quả sẽ được so sánh trên hai bộ dữ liệu: Boston Housing cho bài toán  và MNIST cho bài toán . Mà thang đo cho bài toán  sẽ là Root Mean Square Error (căn bậc hai bình phương trung bình sai số) và accuracy (độ chính xác) đối với bài toán .

<a name="-ket-qua"></a>
## 3.1 Kết quả so sánh

Mạng neuron một lớp ẩn và Perceptron sẽ có số lượng node ở lớp ẩn là $500$, các tham số của các mô hình khác đều được giữ mặc định.

**Kết quả trên bộ dữ liệu Boston Housing**

|Thuật toán|Loại|Thời gian huấn luyện (mili giây)|RMSE trên tập huấn luyện|RMSE trên tập kiểm thử|
|---|---|:---:|:---:|:---:|
|ELM|Neural Network|54.62|4.69|4.82|
|Ridge|Linear Model|2.66|4.72|4.75|
|SVR|Support Vector Machine|26.32|8.25|8.15|
|K-Nearest Neighbors|Nearest Neighbors|1.97|4.98|6.08|
|Decision Tree|Tree-based|7.2|0|5.1|
|Random Forest|Tree-based Ensemble|293.13|1.19|3.8|
|Perceptron (Back-propagation)|Neural Network|237.5|6.94|7.43|


**Kết quả trên bộ dữ liệu MNIST**

|Thuật toán|Loại|Thời gian huấn luyện (mili giây)|Độ chính xác trên tập huấn luyện (%)|Độ chính xác trên tập kiểm thử (%)|
|---|---|:---:|:---:|:---:|
|ELM|Neural Network|4754.13|91.94|92.22|
|Logistic |Linear Model|21112.03|93.39|92.55|
|SVC|Support Vector Machine|280275.89|98.99|97.92|
|K-Nearest Neighbors|Nearest Neighbors|5.07|98.19|96.88|
|Decision Tree|Tree-based|17913.2|100.0|87.68|
|Random Forest|Tree-based Ensemble|37244.7|100.0|96.95|
|Perceptron (Back-propagation)|Neural Network|379703.05|99.73|97.85|

Bạn đọc có thể tham khảo toàn bộ code hiện thực trong bài viết này ở <a href="https://github.com/tuanio/elm-implementation" target="_blank">đây</a>.

<a name="-tong-ket"></a>
# 4. Tổng kết

Qua bài viết này, tôi đã trình bày về cấu trúc của mô hình mạng neuron truyển thẳng một lớp ẩn (SLFN) và vấn đề bất cập trong việc tìm các trọng số của mô hình với thuật toán back-propagation. Từ đó nêu lên thuật toán Extreme Learning Machine giúp giải quyết vấn đề học một cách nhanh và tối ưu. Kết quả thực nghiệm trong phần 3.1 cho thấy rằng tốc độ học của Extreme Learning Machine nhanh hơn hẳn so với back-propagation (mô hình Perceptron), tuy nhiên khi so sánh với các thuật toán đơn giản hơn nhiều như K-Nearest Neighbors thì chưa nhanh bằng, dù gì thì ELM cũng là một mạng neuron nên cấu trúc sẽ phức tạp hơn.

<a name="-tham-khao"></a>
# 5. Tham khảo

<a name="-reference-1"></a>
[1] Guang-Bin Huang, Qin-Yu Zhu, Chee-Kheong Siew, Extreme learning machine: Theory and applications, 2006. <a href="https://doi.org/10.1016/j.neucom.2005.12.126" target="_blank">https://doi.org/10.1016/j.neucom.2005.12.126</a>.