[ { "title": "AutoRec: Autoencoder dành cho Collaborative Filtering", "url": "/posts/autorec/", "categories": "knowledge", "tags": "machine learning, collaborative filtering, recommendation system, movielens dataset, autoencoder, supervised learning, auto-associative neural network", "date": "2022-08-05 01:07:00 +0700", "snippet": "Nội dung 1. Hệ thống khuyến nghị và phương pháp Lọc cộng tác 2. Kiến trúc AutoRec 3. Thực nghiệm với bộ dữ liệu MovieLens 3.1 Chuẩn bị dữ liệu 3.2 Thiết kế mô hình AutoRec 4. Tổng kết 5. Tham khảo1. Hệ thống khuyến nghị và phương pháp Lọc cộng tácHệ thống khuyến nghị (recommendation system), là hệ thống giúp đưa ra khuyến nghị những sản phẩm thích hợp nhất đối với những người dùng cụ thể nào đó. Thường quá trình khuyến nghị này phụ thuộc vào nhiều yếu tố, ví dụ như sản phẩm nào họ đã từng mua, những sản phẩm nào họ đã tương tác (nút like), nhạc nào họ đã từng nghe, món nào họ đã từng ăn hoặc dựa trên những người họ quen biết trên nền tảng điện tử đó, hoặc dựa trên những người dùng có hành vi tương đối giống họ.Vâng, là dựa vào những người dùng có hành vi tương đối giống họ, đây là giải thích ngắn gọn cho phương pháp lọc cộng tác. Phương pháp lọc cộng tác (collaborative filtering) dùng dữ liệu từ những người dùng có hành vi tương đối giống họ (đánh giá dựa trên khoảng cách được tính từ một số yếu tố như có phải bạn bè hay không, các bộ phim đã yêu thích, thể loại đã xem, yêu thích, mức đánh giá …) để đưa ra khuyến nghị cho người dùng đó tương tự như những người dùng này.Có thể bắt gặp nhiều phương pháp lọc cộng tác khác nhau khi tìm từ khoá collaborative filtering, ví dụ như Neighborhood-based, Matrix Factorization (MF), Restricted Bolzmann Machine-based (RBM-based), …, vì các phương pháp này đã được thử nghiệm từ lâu. Nhưng phương pháp mà tôi trình bày trong bài viết này có lẽ vẫn còn mới hơn các phương pháp kể trên nên có thể tìm kiếm sẽ không thấy được, paper gốc của phương pháp này được công bố vào 5/2015.2. Kiến trúc AutoRecTrong paper gốc của AutoRec [1], tác giả sử dụng và chỉnh sửa lại dạng mạng nơ-ron liên kết tự động (auto-associative neural network) Autoencoder. Tác giả sử dụng Autoencoder vì sự thành công của mạng nơ-ron sâu (deep neural network) vào khoảng thời gian tác giả nghiên cứu kiến trúc này. Tác giả tin rằng, AutoRec sẽ có điểm lợi hơn các phương pháp Matrix Factorization và RBM-based về thời gian tính toán và biểu diễn dữ liệu.Đối với một hệ thống điện tử, ta sẽ có $m$ user và $n$ item và trong ngữ cảnh CF, ta sẽ có thêm một ma trận đánh giá (user $u$ đánh giá item $i$) quan sát một phần (không đầy, sẽ có những chỗ là giá trị $0$) user-item $R \\in \\mathbb{R}^{m \\times n}$. Trong rating-based, mỗi user $u \\in U = \\{1 \\cdots m\\}$ được biểu diễn bởi một vector rating quan sát một phần $\\mathrm{r}^{(u)} = (R_{u1}, \\cdots, R_{un}) \\in \\mathbb{R}^n$. Còn trong user-based, mỗi item $i \\in I = \\{1 \\cdots n\\}$ được biểu diễn bởi một vector rating quan sát một phần $\\mathrm{r}^{(i)} = (R_{1i}, \\cdots, R_{mi}) \\in \\mathbb{R}^m$. Mục tiêu của việc sử dụng Autoencoder trong rating-based (hoặc item-based) là nhận một vector quan sát một phần $\\mathrm{r}^{(i)}$ (hoặc $\\mathrm{r}^{(u)}$), chiếu nó xuống không gian ẩn có có số chiều thấp hơn, và tái tạo lại $\\mathrm{r}^{(i)}$ (hoặc $\\mathrm{r}^{(u)}$) tương ứng để dự đoán những rating bị thiếu (những vị trí mà giá trị hiện tại là $0$ hoặc rỗng) cho mục đích khuyến nghị (từ rating dự đoán ta có thể sắp xếp lại các sản phẩm phù hợp để đưa cho người dùng).Cụ thể về mặt toán học, ta có một tập $\\mathrm{S} \\in \\mathbb{R}^d$ gồm các vector và một giá trị $k \\in \\mathbb{N}_{+}$, Autoencoder sẽ giải:\\[\\underset{\\theta}{\\mathrm{min}} \\sum_{\\mathrm{r} \\in \\mathrm{S}}||\\mathrm{r} - h(\\mathrm{r}; \\theta)||^2_{2}\\]trong đó $h(\\mathrm{r}; \\theta)$ là giá trị rating được tái tạo của $\\mathrm{r} \\in \\mathbb{R}^d$,\\[h(\\mathrm{r}; \\theta) = f(\\mathrm{W} \\cdot g(\\mathrm{V}\\mathrm{r}+\\mathrm{\\mu}) + \\mathrm{b})\\]với các activation function $f(\\cdot)$, $g(\\cdot)$. Và bộ các tham số của mô hình $\\theta = \\{\\mathrm{W}, \\mathrm{V}, \\mathrm{r}, \\mathrm{b}\\}$, có kích cỡ lần lượt là $\\mathrm{W} \\in \\mathbb{R}^{d\\times k}$, $\\mathrm{V} \\in \\mathbb{R}^{k\\times d}$ và các bias $\\mathrm{\\mu} \\in \\mathbb{R}^k$, $\\mathrm{b} \\in \\mathbb{R}^d$. Hàm mục tiêu của Autoencoder ở trên là hàm mục tiêu điển hình của mạng nơ-ron tự liên kết, một lớp ẩn có $k$ chiều, và bộ tham số $\\theta$ sẽ được học thông qua back-propagation.Với AutoRec, tác giả sử dụng lại công thức của hàm mục tiêu Autoencoder phía trên, với 2 thay đổi: Chỉ cập nhật những trọng số tương ứng với những quan sát đã có, bằng cách nhân với mask trong quá trình huấn luyện, ta sẽ loại bỏ cập nhật được những quan sát chưa có. Chỉnh hoá các tham số của mô hình để tránh việc Overfit xảy ra.Vì thế, khi áp dụng hàm mục tiêu của Autoencoder với 2 thay đổi trên vào bộ vector rating của Item-based (gọi là I-AutoRec) $\\{\\mathrm{r}^{(i)}\\}^n_{i=1}$ và tham số chỉnh hoá $\\lambda &amp;gt; 0$ bất kỳ, ta sẽ có hàm mục tiêu của AutoRec:\\[\\underset{\\theta}{\\mathrm{min}} \\sum_{i=1}^n||\\mathrm{r^{(i)}} - h(\\mathrm{r^{(i)}}; \\theta)||^2_{\\mathcal{O}} + \\dfrac{\\lambda}{2}\\cdot (||\\mathrm{W}||^{2}_{F} + ||\\mathrm{V}||^{2}_{F})\\]trong đó, kí hiệu \\(\\|\\cdot\\|^{2}_{\\mathcal{O}}\\) thể hiện rằng chỉ xem xét những giá trị đã quan sát được (đã rating). Với User-based (gọi là U-AutoRec), ta áp dụng tương tự đối với tập vector rating $\\{\\mathrm{r}^{(u)}\\}^m_{u=1}$. Tổng quan lại, I-AutoRec sẽ yêu cầu ước lượng $2mk + m + k$ tham số tất cả. Khi đã học được tham số $\\hat{\\theta}$, dự đoán rating của user $u$ dành cho item $i$ là:\\[\\mathrm{R}^{ui} = (h(\\mathrm{r}^{(i))}; \\hat{\\theta}))_{u}\\] Hình 1. Cấu trúc của Item-based AutoRec, các node màu xám thể hiện rating đã có, màu trắng thể hiện không có rating và là giá trị cần dự đoán.Ở trong nghiên cứu, tác giả đề cập đến việc sử dụng các loại activation function khác nhau cho $f(\\cdot)$ và $g(\\cdot)$, bảng dưới đây đánh giá RMSE của các kết hợp (càng thấp càng tốt). Trong đó Identity là không có hàm kích hoạt, còn Sigmoid được định nghĩa ở đây. $f(\\cdot)$ $g(\\cdot)$ RMSE Identity Identity $0.872$ Sigmoid Identity $0.852$ Identity Sigmoid $\\textbf{0.831}$ Sigmoid Sigmoid $0.836$ Trong paper gốc, tác giả đề cập rằng AutoRec rất khác so với các mô hình dành cho CF lúc đó. Cụ thể, khi so sánh AutoRec với RBM-CF, ta có: RBM-CF là dạng mô hình tổng hợp xác suất (generative, probabilistic model) dựa trên RBM. Còn AutoRec là mô hình phân biệt (discriminative model) dựa trên Autoencoder. RBM-CF ước lượng các tham số bằng tối đa hoá log khả năng (maximizing log likelihood), còn AutoRec trực tiếp minimize RMSE, mà đây cũng là cách đánh giá hiệu suất kinh điển trong bài toán dự đoán rating. RBM-CF huấn luyện bằng contrastive divergence, còn AutoRec sử dụng gradient-based backpropagation, mà nhanh hơn nhiều so với RBM-CF. RBM-CF chỉ sử dụng được cho rating dạng rời rạc. Còn AutoRec dùng cho rating dạng liên tục. Với $r$ rating, RBM-CF phải tốn $nkr$ hoặc $mkr$ tham số, trong khi đó AutoRec không quan tâm đến số lượng $r$ nên dùng ít bộ nhớ hơn và khó overfit hơn.Còn khi AutoRec so sánh với Matrix Factorization thì: MF nhúng cả item và user vào không gian ẩn, còn I-AutoRec chỉ nhúng item (U-AutoRec chỉ nhúng user), nên mô hình sẽ nhẹ hơn. MF học một cách biểu diễn ẩn tuyến tính (linear latent representation), còn AutoRec có thể biểu diễn dữ liệu ẩn theo dạng phi tuyến (nonlinear latent representation) thông qua hàm kích hoạt $g(\\cdot)$, mà sẽ tạo được sự tổng quát hoá dữ liệu tốt hơn nhiều.Trong phần sau, chúng ta sẽ đi thực nghiệm AutoRec bằng Pytorch trên bộ dữ liệu Movielens.3. Thực nghiệm với bộ dữ liệu MovielensBộ dữ liệu Movielens là sự lựa chọn số một trong việc đánh giá các hệ thống khuyến nghị vì lượng dữ liệu dồi dào mà nó có. Trong bài viết này, ta sẽ sử dụng bộ Movielens 1 triệu rating để thực nghiệm. Bạn đọc có thể tải về ở đường dẫn sauTheo như ở phần 2 phía trên, ta đề cập đến việc tác giả đưa ra 2 sự thay đổi đối với Autoencoder ban đầu để biến nó thành AutoRec. Ta thấy ở thay đổi thứ 2, mục tiêu của tác giả là tránh overfit cho model và việc tác giả làm đó là sửa đổi hàm loss và phạt các trọng số, thường gọi là chỉnh hóa. Ngoài ra ta biết trong Deep Learning, để tránh overfit cho model, người ta thường sử dụng Dropout với một tỉ lệ hợp lý. Nên trong phần này, tôi sẽ thực nghiệm trên 2 kiến trúc: một là implement lại công thức của tác giả, hai là implement lại theo style của deep learning, thay chỉnh hóa phạt trọng số bằng dropout, kết quả của 2 cách implement cũng một chín một mười với nhau.3.1. Chuẩn bị dữ liệuDữ liệu cần để đưa vào cho model AutoRec là bộ các vector rating (phần này chúng ta sẽ thực nghiệm theo Item-based, nên vector $r$ sẽ được ngầm hiểu là $r^{(i)}$), vì thế ta sẽ cần thiết kế một cách nào đó truyền dạng dữ liệu này vào sao cho tiện lợi nhất.Thường trong các bài toán CF, ta sẽ cần một ma trận user-item (user-item matrix) mà các phần tử của ma trận này là rating của user dành cho item ở vị trí tương ứng. Để tạo được từ bộ dữ liệu Movielens ở trên, ta sẽ tạo một ma trận user-item rỗng, rồi đọc từng dòng rating của file ratings.dat để điền vào ma trận vừa tạo này.Đây là một số thư viện cần import trướcimport torchimport timeimport pandas as pdfrom torch import nn, div, square, normfrom torch.nn import functional as Ffrom torchdata import datapipes as dpfrom sklearn.model_selection import train_test_splitfrom sklearn.metrics import mean_squared_errorfrom torch.utils.data import DataLoaderimport matplotlib.pyplot as pltKhai báo một số biến cần sử dụngdatapath = &#39;ml-1m/&#39;seed = 12device = &#39;cuda&#39; if torch.cuda.is_available() else &#39;cpu&#39;Ta cần biết số lượng user, số lượng item nên phải đọc dữ liệu từ hai file users.dat và movies.dat để lấy thông tin.num_users = pd.read_csv(datapath + &#39;users.dat&#39;, delimiter=&#39;::&#39;, engine=&#39;python&#39;, encoding=&#39;latin-1&#39;, header=None)[0].max()num_items = pd.read_csv(datapath + &#39;movies.dat&#39;, delimiter=&#39;::&#39;, engine=&#39;python&#39;, encoding=&#39;latin-1&#39;, header=None)[0].max()num_users, num_itemsKết quả là có $6040$ user và $3952$ item.(6040, 3952)Thường trong các hệ thống khuyến nghị, người ta sẽ sử dụng một tập các item (hoặc user) cho mục đích huấn luyện và một tập riêng biệt item (hoặc user) khác cho mục đích kiểm thử. Ở đây chúng ta cũng sẽ làm như vậy, ta biết item sẽ có id từ $1$ đến num_items, nên ta sẽ generate một sequence từ $0 \\rightarrow \\text{num_items}$ và chia ra $80\\%$ cho huấn luyện, $20\\%$ cho kiểm thử.train_items, test_items = train_test_split(torch.arange(num_items), test_size=0.2, random_state=seed)train_items.size(), test_items.size()(torch.Size([3161]), torch.Size([791]))Sau đó chúng ta tạo một ma trận user-item rỗng toàn cụcuser_item_mat = torch.zeros((num_users, num_items))Rồi đọc các dòng của file ratings.dat rồi điền vào ma trận rỗng trênratings = pd.read_csv(datapath + &#39;ratings.dat&#39;, encoding=&#39;latin-1&#39;, header=None, engine=&#39;python&#39;, delimiter=&#39;::&#39;)def create_data_from_line(line): user_id, item_id, rating, *_ = line user_item_mat[user_id - 1, item_id - 1] = rating return None# dùng hàm đặc biệt của pandas để code ngắn gọn hơnratings.T.apply(create_data_from_line) Sau khi điền, ta sẽ thấy được tỉ lệ rỗng của ma trận này rất cao, $\\approx 96\\%$torch.where(user_item_mat == 0, 1, 0).sum() / (num_users * num_items)tensor(0.9581)Do model được code trên PyTorch, nên ta sẽ cần một cách để đưa dữ liệu vào model. Ta có thể dùng Dataset rồi truyền dữ liệu vào DataLoader theo batch, hoặc cũng có thể tạo một DataPipes, chia batch và truyền vào DataLoader, trong phần này tôi sử dụng DataPipes (bạn đọc có thể tìm hiểu thêm ở đây).Tạo một hàm để tạo DataPipes từ một mảng (mảng này được lấy từ phần chia train-test ở trên) và một hàm để gom tất cả các phần tử của batch lại thành một Long Tensor.def collate_fn(batch): return torch.LongTensor(batch)def create_datapipe_from_array(array, mode=&#39;train&#39;, batch_size=32, len=1000): pipes = dp.iter.IterableWrapper(array) pipes = pipes.shuffle(buffer_size=len) pipes = pipes.sharding_filter() if mode == &#39;train&#39;: pipes = pipes.batch(batch_size, drop_last=True) else: pipes = pipes.batch(batch_size) pipes = pipes.map(collate_fn) return pipesTạo hai DataPipes train và test từ hàm ở trênbatch_size = 512train_dp = create_datapipe_from_array(train_items, batch_size=batch_size)test_dp = create_datapipe_from_array(test_items, mode=&#39;test&#39;, batch_size=batch_size)Rồi tạo hai DataLoader từ hai DataPipes ở trênnum_workers = 2train_dl = DataLoader(dataset=train_dp, shuffle=True, num_workers=num_workers)test_dl = DataLoader(dataset=test_dp, shuffle=False, num_workers=num_workers)Chỉ cần hai DataLoader này là chúng ta đã có dữ liệu sẵn sàng cho việc thực nghiệm3.2. Thiết kế mô hình AutoRecTa có thể sử dụng AutoRec theo 2 kiểu, tôi sẽ gọi là kiểu công thức và kiểu deep learning từ bây giờ để bạn đọc tiện theo dõi.Nếu theo kiểu công thức, ta sẽ code như thế nàyclass AutoRec(nn.Module): def __init__(self, d, k, lambda_): super().__init__() self.lambda_ = lambda_ self.W = nn.Parameter(torch.randn(d, k)) self.V = nn.Parameter(torch.randn(k, d)) self.mu = nn.Parameter(torch.randn(k)) self.b = nn.Parameter(torch.randn(d)) def regularization(self): return div(self.lambda_, 2) * (square(norm(self.W)) + square(norm(self.V))) def forward(self, r): encoder = self.V.matmul(r.T).T + self.mu return self.W.matmul(encoder.sigmoid().T).T + self.bCòn nếu theo kiểu deep learning, ta sẽ code như thế nàyclass AutoRec(nn.Module): def __init__(self, d, k, dropout): super().__init__() self.seq = nn.Sequential( nn.Linear(d, k), nn.Sigmoid(), nn.Dropout(dropout), nn.Linear(k, d) ) def forward(self, r): return self.seq(r)Ở đây ta thấy là kiểu deep learning sẽ thay phần regularization phía trên thành dropout.Tiếp theo, ta cần định nghĩa hàm train và hàm eval, hai hàm này của hai cách implement chỉ khác nhau ở phần tính loss.Kiểu theo công thứcdef train_epoch(model, dl, opt, criterion): list_loss = [] start_time = time.perf_counter() for batch_idx, items_idx in enumerate(dl): r = user_item_mat[:, items_idx].squeeze().permute(1, 0).to(device) r_hat = model(r) loss = criterion(r, r_hat * torch.sign(r)) + model.regularization() list_loss.append(loss.item()) if batch_idx % 50 == 0: log_time = round(time.perf_counter() - start_time, 4) print(&quot;Loss {:.2f} | {:.4f}s&quot;.format(loss.item(), log_time)) opt.zero_grad() loss.backward() opt.step() return list_lossdef eval_epoch(model, dl, criterion): model.eval() truth = [] predict = [] list_loss = [] start_time = time.perf_counter() with torch.no_grad(): for batch_idx, items_idx in enumerate(dl): r = user_item_mat[:, items_idx].squeeze().permute(1, 0).to(device) r_hat = model(r) truth.append(r) predict.append(r_hat * torch.sign(r)) loss = criterion(r, r_hat * torch.sign(r)) + model.regularization() list_loss.append(loss.item()) if batch_idx % 30 == 0: log_time = round(time.perf_counter() - start_time, 4) print(&quot;Loss {:.2f} | {:.4f}s&quot;.format(loss.item(), log_time)) rmse = torch.Tensor([torch.sqrt(square(r - r_hat).sum() / torch.sign(r).sum()) for r, r_hat in zip(truth, predict)]).mean().item() return list_loss, rmseKiểu deep learningdef train_epoch(model, dl, opt, criterion): list_loss = [] start_time = time.perf_counter() for batch_idx, items_idx in enumerate(dl): r = user_item_mat[:, items_idx].squeeze().permute(1, 0).to(device) r_hat = model(r) loss = criterion(r, r_hat * torch.sign(r)) list_loss.append(loss.item()) if batch_idx % 50 == 0: log_time = round(time.perf_counter() - start_time, 4) print(&quot;Loss {:.2f} | {:.4f}s&quot;.format(loss.item(), log_time)) opt.zero_grad() loss.backward() opt.step() return list_lossdef eval_epoch(model, dl, criterion): model.eval() truth = [] predict = [] list_loss = [] start_time = time.perf_counter() with torch.no_grad(): for batch_idx, items_idx in enumerate(dl): r = user_item_mat[:, items_idx].squeeze().permute(1, 0).to(device) r_hat = model(r) truth.append(r) predict.append(r_hat * torch.sign(r)) loss = criterion(r, r_hat * torch.sign(r)) list_loss.append(loss.item()) if batch_idx % 30 == 0: log_time = round(time.perf_counter() - start_time, 4) print(&quot;Loss {:.2f} | {:.4f}s&quot;.format(loss.item(), log_time)) rmse = torch.Tensor([torch.sqrt(square(r - r_hat).sum() / torch.sign(r).sum()) for r, r_hat in zip(truth, predict)]).mean().item() return list_loss, rmseĐịnh nghĩa model, optimizer và loss functionKiểu theo công thứcmodel = AutoRec(d=num_users, k=500, lambda_=0.0001).to(device)opt = torch.optim.Adam(model.parameters(), lr=0.012, weight_decay=1e-5)criterion = nn.MSELoss().to(device)Kiểu deep learningmodel = AutoRec(d=num_users, k=500, dropout=0.1).to(device)opt = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-5)criterion = nn.MSELoss()Cụ thể hơn về code, bạn đọc có thể tham khảo ở Github respository này.Kết quả sau khi thực nghiệm, ta có bảng dưới đây Kiểu implementation Test Loss RMSE Formula style $0.06$ $\\approx 0.932$ Deep learning style $0.04$ $\\approx 0.947$ Kết quả của tác giả trình bày trong paper gốc trên bộ dữ liệu Movielens 1M có RMSE là $0.831$.4. Tổng kếtTrong bài viết này, tôi đã đi qua sơ lược về hệ thống khuyến nghị và phương pháp lọc cộng tác, từ đó đi qua kiến trúc mô hình AutoRec, một dạng cải tiến của Autoencoder dành cho lọc cộng tác. Qua thực nghiệm, kết quả của cả hai dạng implementation có kết quả không quá chênh lệch nhau. Bạn đọc có thể đọc thêm về paper gốc của tác giả trong phần 5.5. Tham khảo[1] AutoRec: Autoencoders Meet Collaborative Filtering https://doi.org/10.48550/arXiv.2007.07224." }, { "title": "Bài toán Audio Classification", "url": "/posts/audio-classification/", "categories": "knowledge", "tags": "machine learning, audio classification, alexnet, cnn, supervised learning, speech recognition", "date": "2022-05-05 13:55:00 +0700", "snippet": "Nội dung 1. Bài toán Audio Classification 2. Thực nghiệm bài toán Audio Classification với bộ dữ liệu Speech Commands 2.1. Bộ dữ liệu Speech Commands 2.2. Những thành phần cần thiết của Pytorch Lightning cho bài toán 2.3. Kết quả 3. Tổng kết 4. Tham khảo1. Bài toán Audio ClassificationBài toán nhận diện âm thanh là một dạng bài toán phổ thông và có nhiều ứng dụng trong thực tế. Nhiệm vụ của chúng ta trong bài toán này là phân loại được các bản ghi âm thanh thành các thể loại (lớp) đã được quy định sẵn.Đây là một bài toán phân loại bình thường, nhưng cấu trúc dữ liệu âm thanh có thể khác so với dạng ma trận có sẵn khi chúng ta làm phân lớp với mô hình Decision Tree hay Logistic Regression.Hình dưới đây mô tả dạng tín hiệu âm thanh khi được đọc lên từ file. Hình 1: Dạng tín hiệu sóng của một file âm thanh.Ta thấy dạng sóng này có dạng 1D, vậy nên ta có thể sử dụng Convolution 1D để trích xuất thông tin từ tín hiệu. Dạng mô hình M5 là một ví dụ trong trường hợp này [1].Nhưng thay vì xử lý trên dạng tín hiệu sóng thô của âm thanh, ta có thể trích xuất thông tin và chuyển tín hiệu âm thanh thành dạng ảnh để xử lý trên kiến trúc CNN 2D, tiện lợi hơn, đơn giản hơn và phổ biến hơn. Hình dưới đây mô tả dạng Mel Spectrogram sau khi chuyển từ dạng tín hiệu sóng. Ta thấy nó giống hệt một tấm ảnh. Hình 2: Dạng Mel Spectrogram của một file âm thanh.Các bước thực hiện bài toán nhận dạng âm thanh: Chuyển dữ liệu tín hiệu âm thanh thành dạng Mel Spectrogram. Sử dụng một kiến trúc CNN cho bài toán phân loại để học Mel Spectrogram được chuyển từ các file. Đánh giá mô hình.Ta có thể sử dụng bất kì kiến trúc CNN xử lý trên ảnh 2D nào cho bài toán này. Ở đây mình sẽ sử dụng kiến trúc AlexNet [2] cho đơn giản. Hình dưới mô tả AlexNet cho bài toán này, nhận vào một Mel Spectrogram và xuất ra phân bố xác suất với kích cỡ là số lượng lớp của dữ liệu. Hình 3: Kiến trúc AlexNet trong bài toán này.2. Thực nghiệm bài toán Audio Classification với bộ dữ liệu Speech Commands2.1. Bộ dữ liệu Speech CommandsBộ dữ liệu này chứa 35 lớp, với mỗi lớp là tập hợp những file âm thanh ghi âm giọng nói của người nói từ vựng của lớp đó. Các lớp bao gồm những từ vựng dưới đây:labels = [ &quot;house&quot;, &quot;marvin&quot;, &quot;yes&quot;, &quot;bird&quot;, &quot;no&quot;, &quot;on&quot;, &quot;off&quot;, &quot;wow&quot;, &quot;backward&quot;, &quot;happy&quot;, &quot;nine&quot;, &quot;forward&quot;, &quot;left&quot;, &quot;one&quot;, &quot;visual&quot;, &quot;up&quot;, &quot;learn&quot;, &quot;five&quot;, &quot;bed&quot;, &quot;stop&quot;, &quot;dog&quot;, &quot;tree&quot;, &quot;right&quot;, &quot;three&quot;, &quot;zero&quot;, &quot;six&quot;, &quot;two&quot;, &quot;go&quot;, &quot;sheila&quot;, &quot;down&quot;, &quot;seven&quot;, &quot;follow&quot;, &quot;eight&quot;, &quot;cat&quot;, &quot;four&quot;,]Ta sẽ sử dụng bộ dữ liệu này từ thư viện torchaudio cho tiện, không mất công quản lý file.2.2. Những thành phần cần thiết của Pytorch Lightning cho bài toánĐối với Pytorch thông thường, ta sẽ phải chuẩn bị dữ liệu thông qua Dataset, chia batch dữ liệu thông qua DataLoader, chuẩn bị mô hình, chuẩn bị hàm train và hàm validate, lưu lại các thông tin lúc train… . Có quá nhiều thông tin cần quản lý. Thay vào đó, bài viết này mình sẽ thực hiện bằng Pytorch Lightning để tiện quản lý các thành phần. Bạn đọc có thể tìm hiểu kỹ hơn về Pytorch Lightning ở đây.Trước mắt, ta sẽ cần: DataModule: Module quản lý dữ liệu âm thanh theo batch. ModelModule: Module quản lý model, optimizer, scheduler và thao tác thực hiện của hàm train, validate và test.Dưới đây là code của Data Module được đặt trong file datamodule.py:import torchfrom utils import labels2intimport pytorch_lightning as plimport torchaudio.transforms as Tfrom torch.utils.data import DataLoaderfrom torchaudio.datasets import SPEECHCOMMANDSfrom torch.nn.utils.rnn import pad_sequenceclass SpeechCommandDataModule(pl.LightningDataModule): def __init__( self, root: str = &quot;./&quot;, batch_size: int = 64, n_fft: int = 200, pin_memory=False, ): super().__init__() # thư mục lưu dữ liệu self.root = root self.batch_size = batch_size # tạo class MelSpectrogram với số lượng fast fourier transform được chỉ định sẵn self.transform = T.MelSpectrogram(n_fft) self.pin_memory = pin_memory def prepare_data(self): &#39;&#39;&#39; Hàm này để chuẩn bị dữ liệu, tải dữ liệu sẽ được tự gọi khi khởi tạo &#39;&#39;&#39; SPEECHCOMMANDS(self.root, download=True) def setup(self, stage): &#39;&#39;&#39; Hàm này chuẩn bị dữ liệu train, test, val &#39;&#39;&#39; self.train_set = SPEECHCOMMANDS(self.root, subset=&quot;training&quot;) self.test_set = SPEECHCOMMANDS(self.root, subset=&quot;testing&quot;) self.val_set = SPEECHCOMMANDS(self.root, subset=&quot;validation&quot;) def train_dataloader(self): &#39;&#39;&#39; DataLoader của hàm train &#39;&#39;&#39; return DataLoader( self.train_set, batch_size=self.batch_size, collate_fn=self.__collate_fn, pin_memory=self.pin_memory, shuffle=True, # shuffle dữ liệu để tạo sự đa dạng ) def val_dataloader(self): &#39;&#39;&#39; DataLoader của hàm validate &#39;&#39;&#39; return DataLoader( self.val_set, batch_size=self.batch_size, collate_fn=self.__collate_fn, pin_memory=self.pin_memory, ) def test_dataloader(self): &#39;&#39;&#39; DataLoader của hàm test &#39;&#39;&#39; return DataLoader( self.test_set, batch_size=self.batch_size, collate_fn=self.__collate_fn, pin_memory=self.pin_memory, ) def __collate_fn(self, batch): &#39;&#39;&#39; Hàm này sẽ nhận vào một batch và chuyển các dữ liệu âm thanh thành dạng Mel Spectrogram pad thêm số 0 vào để kích cỡ bằng nhau phục vụ cho việc nhân ma trận của mô hình. &#39;&#39;&#39; mel_specs = [self.transform(i[0]).squeeze().permute(1, 0) for i in batch] labels = torch.LongTensor([labels2int.get(i[2]) for i in batch]) mel_specs = pad_sequence(mel_specs, batch_first=True) # thêm 3 channel # do mô hình alexnet yêu cầu đầu vào là một ảnh có 3 channel # nên ta sẽ xếp chồng 3 lần tấm ảnh mel spectrogram lên để có 3 channel mel_specs = torch.stack([mel_specs, mel_specs, mel_specs], dim=1) return mel_specs, labelsDưới đây là code Model Module của file model.py:import torchfrom torch import nnimport pytorch_lightning as plfrom torchvision.models.alexnet import AlexNetclass ModelModule(pl.LightningModule): def __init__( self, num_classes: int = 10, dropout: float = 0.5, lr: float = 0.01, optim_configs: dict = {} ): super().__init__() self.alexnet = AlexNet(num_classes=num_classes, dropout=dropout) self.lr = lr self.optim_configs = optim_configs def forward(self, x: torch.Tensor): &#39;&#39;&#39;hàm này để dự đoán&#39;&#39;&#39; output = self.alexnet(x) return output.argmax(dim=-1) def configure_optimizers(self): # dùng adam optimizer optimizer = torch.optim.Adam( self.parameters(), lr=self.lr, **self.optim_configs ) return optimizer def training_step(self, batch, batch_idx): &#39;&#39;&#39; Hàm này nhận vào một batch lấy kết quả của mô hình và tính loss mô hình sẽ tự tính back propagation &#39;&#39;&#39; x, y = batch out = self.alexnet(x) loss = nn.functional.cross_entropy(out, y) # lưu lại loss của train self.log(&quot;train_loss&quot;, loss.item()) self.log(&quot;lr&quot;, self.lr) return loss def validation_step(self, batch, batch_idx): &#39;&#39;&#39; Hàm này nhận vào một batch lấy kết quả của mô hình và tính loss &#39;&#39;&#39; x, y = batch out = self.alexnet(x) loss = nn.functional.cross_entropy(out, y) # lựa chọn lớp có xác suất cao nhất để làm dự đoán pred = out.argmax(dim=-1) # tính accuracy acc = (pred == y).sum() / y.size(0) # lưu lại loss của validate self.log(&quot;val_loss&quot;, loss.item()) self.log(&quot;val_acc&quot;, acc.item()) return loss, acc def test_step(self, batch, batch_idx): x, y = batch out = self.alexnet(x) loss = nn.functional.cross_entropy(out, y) # lựa chọn lớp có xác suất cao nhất để làm dự đoán pred = out.argmax(dim=-1) # tính accuracy acc = (pred == y).sum() / y.size(0) # lưu lại loss của test self.log(&quot;test_loss&quot;, loss.item()) self.log(&quot;test_acc&quot;, acc.item()) return loss, accTa thấy các thao tác như train, test, validate, chuẩn bị dataloader, optimizer, scheduler, lưu lại loss, lưu lại accuracy được quản lý bởi hai lớp SpeechCommandDataModule và ModelModule, gọn hơn nhiều so với việc quản lý từng thành phần riêng lẻ.Do label của chúng ta là chữ, nên ta sẽ quản lý lại thành các số, từ đó tiện cho mô hình tính toán loss.File utils.py:# số sang label chữlabels = [ &quot;house&quot;, &quot;marvin&quot;, &quot;yes&quot;, &quot;bird&quot;, &quot;no&quot;, &quot;on&quot;, &quot;off&quot;, &quot;wow&quot;, &quot;backward&quot;, &quot;happy&quot;, &quot;nine&quot;, &quot;forward&quot;, &quot;left&quot;, &quot;one&quot;, &quot;visual&quot;, &quot;up&quot;, &quot;learn&quot;, &quot;five&quot;, &quot;bed&quot;, &quot;stop&quot;, &quot;dog&quot;, &quot;tree&quot;, &quot;right&quot;, &quot;three&quot;, &quot;zero&quot;, &quot;six&quot;, &quot;two&quot;, &quot;go&quot;, &quot;sheila&quot;, &quot;down&quot;, &quot;seven&quot;, &quot;follow&quot;, &quot;eight&quot;, &quot;cat&quot;, &quot;four&quot;,]# label chữ sang sốlabels2int = dict(zip(labels, range(len(labels))))Cuối cùng, ta tập hợp tất cả lại để trong file main.py.import hydraimport argparsefrom omegaconf import OmegaConf, DictConfigfrom datamodule import SpeechCommandDataModulefrom model import ModelModuleimport pytorch_lightning as plif __name__ == &quot;__main__&quot;: parser = argparse.ArgumentParser(description=&quot;Config path&quot;) parser.add_argument(&quot;-cp&quot;, help=&quot;config path&quot;) # config path parser.add_argument(&quot;-cn&quot;, help=&quot;config name&quot;) # config name args = parser.parse_args() @hydra.main(config_path=args.cp, config_name=args.cn) def main(cfg: DictConfig): dm = SpeechCommandDataModule(**cfg.datamodule) model = ModelModule(**cfg.model) logger = pl.loggers.tensorboard.TensorBoardLogger(**cfg.logger) trainer = pl.Trainer(logger=logger, **cfg.trainer) trainer.fit(model, datamodule=dm) trainer.test(model, datamodule=dm) main()Ở đây, mình sử dụng một thư viện tên là hydra để quản lý các tinh chỉnh của tất cả thành phần trong code, như vậy khi huấn luyện sẽ không cần sửa code mà chỉ cần tinh chỉnh file configs là được.Đây là file configs mẫu của mình. Bạn đọc có thể tinh chỉnh lại cho phù hợp với mỗi máy cá nhân.datamodule: root: /kaggle/working/ # thư mục gốc để chứa dữ liệu sẽ được tải về batch_size: 128 # batch size của dataloader n_fft: 200 # số lượng fourier transform pin_memory: True # True if gpumodel: num_classes: 35 # số lượng lớp của dữ liệu dropout: 0.1 # tỉ lệ dropout lr: 0.001 # learning rate khởi tạo optim_configs: weight_decay: 0.0001logger: save_dir: tb_logs # thư mục lưu log của tensorboard name: alexnet_logs # tên của logtrainer: max_epochs: 10 # số epoch tối đa accelerator: auto # có thể là cpu, gpu, tpu. Auto sẽ tự lựa chọn dựa trên môi trường.Bạn đọc có thể huấn luyện mô hình trên máy cá nhân hoặc Colab, đối với mình, mình sẽ huấn luyện trên Kaggle.Đây là link Kaggle mình sử dụng để config và train model này, bạn đọc có thể tham khảo Kaggle.2.3. Kết quảDo Pytorch Lightning lưu kết quả để tiện theo dõi trong Tensorboard, nên ta có thể theo dõi thông qua nó.Dưới đây là thông tin loss của tập dữ liệu train. Ta thấy loss giảm rất nhanh trong 1000, 2000 step đầu tiên, sau đó có thể learning rate vẫn hơi cao nên giao động loss xảy ra. Có lẽ chúng ta nên thêm một Learning Rate Scheduler vào mô hình, bạn đọc có thể thử nghiệm xem kết quả như thế nào. Nhưng tổng quan hình 4 thì ta thấy loss giảm, chứng tỏ mô hình đang học đúng hướng. Hình 4: Loss theo thời gian của mô hình trên tập dữ liệu train.Dưới đây là thông tin loss của tập dữ liệu validate. Loss của tập validate cũng giảm nên ta cũng ngầm hiểu mô hình đang học đúng. Hình 5: Loss theo thời gian của mô hình trong quá trình validate.Độ chính xác của tập dữ liệu validate. Ở đây, ta thấy độ chính xác (accuracy) tăng theo thời gian, chứng tỏ mô hình càng ngày càng cải thiện và mô hình học được tốt. Độ chính xác và loss cuối cùng của tập validate được thể hiện ở hình 7. Hình 6: Độ chính xác theo thời gian của mô hình trong quá trình validate Hình 7: Độ chính xác và loss cuối cùng của tập validate3. Tổng kếtBài viết này đã đi qua về định nghĩa bài toán nhận diện âm thanh và thực nghiệm trên bộ dữ liệu Speech Commands với mô hình AlexNet. Chúng ta thấy độ chính xác cuối cùng vào khoảng $73%$, không quá cao nhưng thể hiện được mô hình này có thể hoạt động tốt. Bạn đọc có thể thêm Learning Rate Scheduler, tinh chỉnh Optimizer, điều chỉnh learning rate, train thêm nhiều epoch và chỉnh sửa các thông tin khác để mô hình hoạt động tốt hơn.Bạn đọc có thể tham khảo thêm về: Tổng hợp code của bài toán: Audio Classification - Github. Code thực nghiệm mô hình: Speech Commands Audio Classification - Kaggle.4. Tham khảo[1] Very Deep Convolutional Neural Networks For Raw Waveforms https://arxiv.org/pdf/1610.00087.pdf.[2] ImageNet classification with deep convolutional neural networks https://dl.acm.org/doi/10.1145/3065386." }, { "title": "Autoencoder và bài toán phát hiện bất thường trong an ninh mạng", "url": "/posts/autoencoder/", "categories": "knowledge", "tags": "machine learning, autoencoder, feedforward neural network, nsl-kdd dataset, unsupervised learning, representation learning, anomaly detection", "date": "2022-01-16 15:33:00 +0700", "snippet": "Nội dung 1. Giới thiệu Autoencoder 2. Bài toán phát hiện bất thường trong an ninh mạng 3. Thực nghiệm Autoencoder với bộ dữ liệu NSL-KDD 3.1 Giới thiệu bộ dữ liệu NSL-KDD 3.2 Hiện thực 4. Tổng kết 5. Tham khảo1. Giới thiệu AutoencoderAutoencoder là một mạng neuron truyền thẳng học không giám sát (unsupervised feedforward neural network). Mục đích của Autoencoder là cố gắng tái tạo dữ liệu đầu vào sao cho giống nhất có thể. Autoencoder thường được dùng trong các bài toán giảm chiều dữ liệu, khử nhiễu từ ảnh hoặc phát hiện bất thường, trong bài viết này, chúng ta sẽ tập trung vào bài toán phát hiện bất thường. Hình 1: Cấu trúc cơ bản của AutoencoderMột mạng Autoencoder có thể chia thành 3 thành phần chính: encoder $f(x)$, code $h$ và decoder $g(h)$. Cụ thể thì mạng sẽ trông như hình 1. Lớp code còn được gọi là lớp đại diện, thường thì sẽ có kích cỡ nhỏ nhất trong mạng, tác dụng chính của lớp này dùng để lưu trữ những thông tin quan trọng nhất từ dữ liệu đầu vào. Trong khi đó, lớp encoder cố gắng đưa dữ liệu đầu vào thành lớp code, còn lớp decoder cố gắng tái tạo lại dữ liệu đầu ra từ lớp code. Nếu coi $x$ là dữ liệu đầu vào, $r$ là dữ liệu tái tạo từ lớp decoder, ta có thể hiểu là: $h=f(x)$, $r=g(h)$. Autoencoder thực chất cũng là mạng neuron, nên có thể huấn luyện thông qua back-propagation với hàm lỗi là $L(x, r)$, thường thì hàm lỗi sẽ là Mean Square Error.Cấu trúc của encoder, code và decoder trong mỗi dạng, bài toán sử dụng Autoencoder sẽ khác nhau. Một mạng Autoencoder đơn giản sẽ chỉ có 3 lớp ẩn, tương ứng với 3 lớp encoder, code và decoder, trong đó encoder và decoder có kích cỡ giống nhau, code sẽ có kích cỡ nhỏ. Còn một mạng Deep Autoencoder sẽ xếp chồng nhiều lớp ẩn lại và thu nhỏ kích cỡ lần lượt trong encoder, decoder sẽ là phiên bản ngược lại của encoder. Hình 2 mô tả cấu trúc của mạng Deep Autoencoder. Deep Autoencoder đặc biệt thích hợp trong bài toán phát hiện bất thường. Hình 2: Cấu trúc của Deep Autoencoder2. Bài toán phát hiện bất thường trong an ninh mạngBất thường, tiếng anh là anomaly, outliers là những dữ liệu trông có vẻ khác xa so với đa số dữ liệu chúng ta có. Có thể là một điểm có giá trị rất lớn trong tập dữ liệu mà đa phần chỉ toàn giá trị nhỏ.Trong lĩnh vực an ninh mạng, dữ liệu sẽ là những thông tin trong mạng, như thời gian gửi gói tin, độ trễ, thời gian chờ,… . Đa phần người sử dụng mạng trong một mạng lưới là người dùng bình thường, không có mục đích tấn công vào một trụ sở, nên dữ liệu của mỗi người sẽ tương đối giống nhau. Nhưng đối với những người dùng có ý đồ xấu, gọi là hacker, dữ liệu mạng này sẽ khác so với dữ liệu của một người dùng bình thường, nguyên nhân là các hacker sẽ dùng các phương pháp tấn công đặc biệt, mà trong quá trình thao tác, dữ liệu mạng sẽ bị biến đổi theo cách khác. Ta có thể dựa vào đó để phát hiện xâm nhập trong an ninh mạng.Mục đích của Autoencoder sẽ là cố gắng tái tạo dữ liệu đầu vào sao cho giống nhất với dữ liệu huấn luyện. Dựa vào thông tin này, ta có thể chỉ đưa dữ liệu thuộc lớp normal là dữ liệu bình thường, không phải bất thường cho Autoencoder học. Sau đó ta sẽ đi tính lỗi tái tạo (reconstruction error) trên cả tập dữ liệu normal lẫn abnormal, nếu độ lỗi tái tạo càng nhỏ, có nghĩa là việc Autoencoder tái tạo tập normal là đúng, ngược lại, độ lỗi tái tạo cao, nghĩa là dữ liệu đầu vào khác so với normal, nghĩa là abnormal, lúc này độ lỗi tái tạo giống như một histogram, ta chỉ cần tìm một ngưỡng để phân tách hai tập lỗi của normal và abnormal. Bài toán lúc này trở thành bài toán phân loại nhị phân (binary classification).3. Thực nghiệm Autoencoder với bộ dữ liệu NSL-KDD3.1 Giới thiệu bộ dữ liệu NSL-KDDBộ dữ liệu NSL-KDD khá nổi tiếng, được cải thiện từ bộ dữ liệu KDD’99. Dữ liệu này là về những thông tin mạng được thu thập bởi các nhà nghiên cứu, dữ liệu được chia thành nhiều nhãn, nhãn normal là thông tin gói tin bình thường từ người dùng bình thường và các nhãn khác như của các phương thức tấn công như neptune, warezclient, ipsweep, portsweep, v.v là của những người dùng có ý đồ xấu, gọi là hacker. Nhưng chúng ta sẽ coi tất cả phương thức tấn công như nhãn abnormal cho gọn. Bạn đọc có thể xem thêm chi tiết về bộ dữ liệu ở đây3.2 Hiện thựcBài toán sẽ được hiện thực bằng ngôn ngữ lập trình Python, kết hợp thêm thư viện Tensorflow để xây dựng mô hình Autoencoder.Trước tiên ta sẽ đọc dữ liệu lên, bao gồm cả dữ liệu huấn luyện từ KDDTrain+.txt và dữ liệu kiểm thử KDDTest+.txt, đây là hai tập dữ liệu đầy đủ nhất, các tập dữ liệu còn lại được trích ra từ hai tập này.Các thư viện được sử dụng trong hiện thực:import pandas as pdimport numpy as npimport seaborn as snsimport matplotlib.pyplot as pltimport tensorflow as tffrom tensorflow import kerasfrom sklearn.metrics import accuracy_score, confusion_matrixfrom sklearn.preprocessing import OneHotEncoder, MinMaxScalerĐọc dữ liệu lên bằng pandas.train = pd.read_csv(&#39;NSL-KDD-Dataset/KDDTrain+.txt&#39;, header=None)test = pd.read_csv(&#39;NSL-KDD-Dataset/KDDTest+.txt&#39;, header=None)Nói sơ qua về tập dữ liệu thì chúng ta có 43 cột, bao gồm các kiểu dữ liệu số và chữ. Cột dữ liệu cuối cùng là cột difficulty, theo link ở trên phần 3.1, nó không có tác dụng mấy trong việc xác định bất thường, nên ta sẽ bỏ đi. Cột dữ liệu kế cuối, có chỉ số là 41 là cột label của dữ liệu, bao gồm normal và các phương thức tấn công khác, mà ta lại muốn chuyển các phương thức tấn công thành abnormal, nên cuối cùng cột này sẽ chỉ có 2 giá trị duy nhất: normal và abnormal. Ngoài ra các cột dữ liệu chữ khác cũng cần được chuyển sang dạng OneHot, nghĩa là các giá trị chữ sẽ được chuyển thành một vector có độ dài bằng số lượng giá trị chữ duy nhất, sẽ điền giá trị 1 vào nếu phần tử tương ứng xuất hiện, ngược lại là 0, bạn đọc có thể tìm hiểu về OneHot ở đây. Các cột dữ liệu số không có khoảng giống nhau, như thế sẽ khiến cho mô hình hội tụ chậm hơn, nên ta cũng cần scale về $[0, 1]$ để tiện cho hàm activation sigmoid được sử dụng trong mô hình Autoencoder về sau.Ta sẽ định nghĩa hai lớp dùng cho việc mã hóa OneHot và scale dữ liệu:encoder = OneHotEncoder(handle_unknown=&#39;ignore&#39;)scaler = MinMaxScaler()Và định nghĩa một hàm để xử lý dữ liệu, dùng cho cả tập huấn luyện và kiểm thử đọc ở trên.def preprocess(df, is_fit=True): # chuyển normal thành 1 và các lớp khác thành 0 label = np.where(df[41] == &#39;normal&#39;, &#39;normal&#39;, &#39;abnormal&#39;) # loại bỏ cột dữ liệu không cần thiết df.drop([41, 42], axis=1) # chia dữ liệu ra số, chữ để tiện xử lý numerical_data = df.select_dtypes(exclude=&#39;object&#39;).values categorical_data = df.select_dtypes(include=&#39;object&#39;).values # chỉ fit với dữ liệu train if is_fit: encoder.fit(categorical_data) # chuyển từ dữ liệu chữ sang onehot categorical_data = encoder.transform(categorical_data).toarray() # nối dữ liệu số và onehot lại data = np.concatenate([numerical_data, categorical_data], axis=1) # chỉ fit với dữ liệu train if is_fit: scaler.fit(data) # dữ liệu chuẩn hóa về dạng [0, 1] data = scaler.transform(data) return dict(data=data, label=label)Sau đó đi xử lý cho hai tập. Một lưu ý nhỏ ở đây là ta cần cả hai tập huấn luyện và kiểm thử sau khi xử lý phải có số cột giống nhau, scale dữ liệu cũng sẽ giống nhau. Nên ta chỉ cần fit dữ liệu huấn luyện vào encoder và scaler, tập huấn luyện sẽ chỉ dùng lại dữ liệu đã fit, nên cả hai tập dữ liệu sẽ có số lượng cột giống nhau sau khi xử lý.# xử lý dữ liệutrain = preprocess(train, True)test = preprocess(test, False)Dữ liệu sau khi xử lý sẽ có cùng số lượng cột.train[&#39;data&#39;].shape, test[&#39;data&#39;].shape((125973, 146), (22544, 146))Tiếp theo ta sẽ định nghĩa kiến trúc của Autoencoder. Lớp encoder sẽ có các lớp lần lượt là 64 -&amp;gt; 32 -&amp;gt; 16 -&amp;gt; 8. Lớp decoder sẽ có kích cỡ là 16 -&amp;gt; 32 -&amp;gt; 64 -&amp;gt; 146. Ở đây, 8 là lớp code, là lớp nhỏ nhất, đại diện cho thông tin quan trọng nhất đã được mã hóa, 146 là kích cỡ dữ liệu đầu vào, do ta muốn kích cỡ đầu ra phải giống hệt đầu vào. Ngoài lớp cuối cùng dùng hàm kích hoạt sigmoid để tạo dữ liệu về scale $[0, 1]$, thì các lớp còn lại sẽ dùng hàm kích hoạt tanh. Dưới đây mô tả lớp Autoencoder được thiết kế. Ngoài ra, ta sẽ tạo thêm hàm get_construction_error để tính lỗi tái tạo, hàm predict_class sẽ đi dự đoán ra lớp normal hay abnormal cụ thể.class Autoencoder(keras.Model): def __init__(self, input_dim): super(Autoencoder, self).__init__() self.encoder = keras.Sequential([ keras.layers.Dense(64, activation=&#39;tanh&#39;), keras.layers.Dense(32, activation=&#39;tanh&#39;), keras.layers.Dense(16, activation=&#39;tanh&#39;), keras.layers.Dense(8, activation=&#39;tanh&#39;) ]) self.decoder = keras.Sequential([ keras.layers.Dense(16, activation=&#39;tanh&#39;), keras.layers.Dense(32, activation=&#39;tanh&#39;), keras.layers.Dense(64, activation=&#39;tanh&#39;), keras.layers.Dense(input_dim, activation=&#39;sigmoid&#39;), ]) def call(self, x): code = self.encoder(x) r = self.decoder(code) return r def get_reconstruction_error(self, x): r = self.predict(x) return keras.metrics.mean_squared_error(x, r) def predict_class(self, x, threshold): reconstruction_error = self.get_reconstruction_error(x) return np.where(reconstruction_error &amp;lt;= threshold, &#39;normal&#39;, &#39;abnormal&#39;)Ta sẽ đem chia các tập dữ liệu ra để tiện cho quá trình huấn luyện và kiểm thử.# chia dữ liệutrain_normal = train[&#39;data&#39;][train[&#39;label&#39;] == &#39;normal&#39;]train_abnormal = train[&#39;data&#39;][train[&#39;label&#39;] == &#39;abnormal&#39;]test_normal = test[&#39;data&#39;][test[&#39;label&#39;] == &#39;normal&#39;]test_abnormal = test[&#39;data&#39;][test[&#39;label&#39;] == &#39;abnormal&#39;]Ta định nghĩa optimizer và loss function cho mô hình Autoencoder trên, optimizer có thể sử dụng là Adam, một dạng của Gradient-Descent, loss function có thể sử dụng là Mean Square Error, đo lường sự sai khác của dữ liệu số.model = Autoencoder(train_normal.shape[1])optimizer = keras.optimizers.Adam()loss_fn = keras.losses.MeanSquaredError()model.compile(optimizer, loss_fn)Đem huấn luyện mô hình với batch size là 64 và số lượng lần lặp epochs là 100. Các bạn có thể dùng runtime GPU của Google Colab để tăng tốc quá trình huấn luyện.model.fit(train_normal, train_normal, batch_size=64, epochs=100)Sau khi huấn luyện, ta sẽ mong muốn tính độ lỗi tái tạo của tập dữ liệu huấn luyện và tập kiểm thử để xem phân phối lỗi như thế nào.# tính độ lỗi tái tạo cho tất cả các tập dữ liệutrain_normal_re = model.get_reconstruction_error(train_normal)train_abnormal_re = model.get_reconstruction_error(train_abnormal)test_normal_re = model.get_reconstruction_error(test_normal)test_abnormal_re = model.get_reconstruction_error(test_abnormal)Ta muốn có một ngưỡng $\\theta_\\alpha$ sao cho có thể phân chia tốt cả hai tập lỗi này. $\\alpha$ tôi chọn trong bài là $0.5$, nhưng các bạn có thể tùy chỉnh theo dữ liệu của các bạn.# tìm ngưỡng alpha từ tập trainalpha = 0.5threshold = np.concatenate([train_normal_re, train_abnormal_re]).mean() * alphaprint(&#39;Ngưỡng vừa tìm được từ tập train:&#39;, threshold)Ngưỡng vừa tìm được từ tập train: 0.012324278242886066Vẽ dữ liệu lên sẽ trông như thế này (hình 3 và 4). Độ lỗi normal bị lọt thỏm ở khoảng $0$, nghĩa là về cơ bản tái tạo giống hệt như ban đầu, còn độ lỗi abnormal khá là cao và phân phối rộng. Chỉ cần nhìn vào là ta đã biết được dữ liệu đó là thuộc lớp nào, điểm ngưỡng threshold sẽ giúp ta làm điều đó một cách chính xác hơn. Hình 3: Histogram phân phối lỗi của tập huấn luyện Hình 4: Histogram phân phối lỗi của tập kiểm thửĐộ chính xác trong việc phân loại hai tập dữ liệu khá cao: tập huấn luyện là 99% và tập kiểm thử là 96%.train_label_predict = model.predict_class(train[&#39;data&#39;], threshold)print(&#39;Độ chính xác tập huấn luyện&#39;, end=&#39;: &#39;)accuracy_score(train[&#39;label&#39;], train_label_predict)Độ chính xác tập huấn luyện: 0.9978169925301453test_label_predict = model.predict_class(test[&#39;data&#39;], threshold)print(&#39;Độ chính xác tập kiểm thử&#39;, end=&#39;: &#39;)accuracy_score(test[&#39;label&#39;], test_label_predict)Độ chính xác tập kiểm thử: 0.9633161816891412Dưới đây là confusion matrix của hai tập dữ liệu. Hình 5: Confusion matrix của tập huấn luyện Hình 6: Confusion matrix của tập kiểm thửToàn bộ code bạn đọc có thể lấy ở đây.4. Tổng kếtQua bài viết này, tôi đã giới thiệu về mô hình mạng neuron Autoencoder và ứng dụng của nó trong bài toán phát hiện bất thường trong an ninh mạng với bộ dữ liệu NSL-KDD. Kết quả sau khi thực nghiệm đạt độ chính xác cao. Bạn đọc có thể tìm hiểu thêm các dạng khác của Autoencoder như Sparse Autoencoder, Stack Autoencoder, Variational Autoencoder, v.v. Với mỗi dạng, sẽ có thể ứng dụng vào một bài toán nào đó khác nhau.5. Tham khảo[1] Ian Goodfellow, Yoshua Bengio, Aaron Courville. Deep Learning. 2016. MIT Press. http://www.deeplearningbook.org.[2] Wikipedia. Autoencoder. https://en.wikipedia.org/wiki/Autoencoder.[3] Arden Dertat. Applied Deep Learning - Part 3: Autoencoders. 03/10/2017. https://towardsdatascience.com/applied-deep-learning-part-3-autoencoders-1c083af4d798." }, { "title": "Extreme Learning Machine: Thuật toán học nhanh cho mạng neuron truyền thẳng một lớp ẩn", "url": "/posts/elm/", "categories": "knowledge", "tags": "machine learning, elm, feedforward neural network, mnist dataset, boston housing dataset", "date": "2022-01-10 21:07:00 +0700", "snippet": "Nội dung 1. Mạng neuron truyền thẳng một lớp ẩn 1.1 Định nghĩa 1.2 Bài toán học tham số 2. Thuật toán Extreme Learning Machine 3. Thực nghiệm thuật toán Extreme Learning Machine với hai bài toán: Regression và Classification 3.1 Kết quả 4. Tổng kết 5. Tham khảo1. Mạng neuron truyền thẳng một lớp ẩn1.1 Định nghĩaMạng neuron truyền thẳng một lớp ẩn (single hidden layer feedforward networks - SLFN) là một mạng neuron nhân tạo, mà các kết nối truyền thẳng từ đầu vào đến đầu ra. Đây là mô hình machine learning khá tốt được sử dụng trong rất nhiều lĩnh vực, SLFN có khả năng xấp xỉ một tập dữ liệu phức tạp trực tiếp từ dữ liệu đầu vào.Cấu trúc của mạng neuron truyền thẳng một lớp ẩn bao gồm: 1 lớp đầu vào, 1 lớp ẩn và một lớp đầu ra. Hình 1 mô tả cấu trúc này. Hình 1: Cấu trúc của mạng neuron truyền thẳng một lớp ẩnGiả sử ta có $N$ mẫu dữ liệu, mỗi mẫu là cặp $(\\mathrm{x}_i, \\mathrm{t}_i)$, trong đó: Vector \\(\\mathrm{x}_i = [x_{i1}, x_{i2}, \\cdots, x_{in}] \\in \\mathrm{R}^n\\) là dữ liệu đầu vào. Vector \\(\\mathrm{t}_i = [x_{i1}, x_{i2}, \\cdots, x_{im}] \\in \\mathrm{R}^m\\) là dữ liệu đầu ra.Một cấu trúc của mạng neuron một lớp ẩn sẽ chứa những thành phần sau: Lớp ẩn có $\\tilde{N}$ node. Hàm kích hoạt (activation function) cho lớp ẩn gọi là $g(x)$. Ma trận trọng số dùng để kết nối dữ liệu đầu vào và lớp ẩn là \\(\\mathrm{W}_{nN} = [\\mathrm{w}_1, \\mathrm{w}_2, \\cdots, \\mathrm{w}_{\\tilde{N}}]\\), trong đó \\(\\mathrm{w}_i=[w_{i1}, w_{i2}, \\cdots, w_{in}]^\\intercal\\). Vector ngưỡng \\(\\mathrm{b}_i=[b_1, b_2, \\cdots, b_{\\tilde{N}}]\\) để cộng thêm cho mỗi node ẩn. Ma trận trọng số kết nối lớp ẩn với lớp đầu ra là \\(\\beta = [\\beta_{1}, \\beta_{2}, \\cdots, \\beta_{\\tilde{N}}]\\), với \\(\\beta_i=[\\beta_{i1}, \\beta_{i2}, \\cdots, \\beta_{im}]^\\intercal\\)Ta có thể viết các thành phần trên dưới dạng mô hình toán học như sau:\\[\\sum_{i=1}^{\\tilde{N}} \\beta_i g_i(\\mathrm{x}_j)=\\sum_{i=1}^{\\tilde{N}} \\beta_i g_i(\\mathrm{w}_i \\cdot \\mathrm{x}_j + b_i)=\\mathrm{o}_j, j=1, \\cdots, N\\]Mà vector $o_j$ chính là kết quả đầu ra của mạng neuron. Mục tiêu của chúng ta khi xây dựng mô hình là tìm được bộ trọng số $\\mathrm{W}$, $\\mathrm{b}$ và $\\beta$ sao cho tối thiểu hóa sự khác nhau giữa đầu ra của mô hình $\\mathrm{o}_j$ và đầu ra thực tế $\\mathrm{t}_j$, cụ thể hơn là ta muốn sự sai khác bằng $0$!:\\[\\sum_{i=1}^{\\tilde{N}} ||\\mathrm{o}_j - \\mathrm{t}_j||=0\\]1.2 Bài toán học tham sốBài toán bây giờ là làm sao để học mạng neuron một lớp ẩn một cách tối ưu. Thông thường, ta có thể nghĩ đến thuật toán lan truyền ngược (back-propagation) kết hợp với gradient-descent để tối ưu bài toán qua các lần lặp. Nhưng thuật toán lan truyền ngược không hoàn hảo, tồn tại những nhược điểm của nó như là: Khi learning rate quá nhỏ, thuật toán hội tụ rất lâu. Tuy nhiên khi learning rate quá lớn, thuật toán sẽ không ổn định và trở nên phân kỳ. Thuật toán dễ rơi vào local minima, mà chúng ta muốn thuật toán sẽ chạy xuống global minima, là điểm tối ưu nhất của bài toán (vì muốn sự sai khác bằng $0$ tuyệt đối). Mạng neuron có thể bị quá khớp (overfit) hoặc không có khả năng tổng quát hóa (underfit) khi huấn luyện bằng back-propagation, vì vậy phải có một hàm chi phí, tiêu chí đánh giá, thời điểm dừng thích hợp và các siêu tham số khác phải tinh chỉnh. Các dạng thuật toán học theo kiểu gradient rất tốn thời gian trong hầu hết các bài toán. Trong khi ta lại muốn giải một bài toán đơn giản nhanh chóng.Chung quy 4 nhược điểm trên, ta thấy back-propagation tốn thời gian và không phải lúc nào cũng sẽ tối ưu. Vì thế, ta cần một cách nhanh hơn và tối ưu hơn để giải bài toán ở trên, mà phần tiếp theo sẽ trình bày thuật toán Extreme Learning Machine để thay thế cho back-propagation trong ngữ cảnh bài toán này.2. Thuật toán Extreme Learning MachineTrước tiên thì ta hãy nhìn lại vấn đề một chút. Vì chúng ta muốn sự sai khác tuyệt đối bằng $0$, nên sẽ tồn tại bộ trọng số $\\mathrm{w}_i$, $\\beta_i$ và $b_i$ để mà:\\[\\sum_{i=1}^{\\tilde{N}} \\beta_i g_i(\\mathrm{w}_i \\cdot \\mathrm{x}_j + b_i)=\\mathrm{t}_j, j=1, \\cdots, N\\]Ta có thể viết công thức trên dưới dạng ma trận như sau:\\[\\mathrm{H}\\beta = \\mathrm{T}\\]Mà:\\[\\mathrm{H}(\\mathrm{w}_1, \\cdots, \\mathrm{w}_{\\tilde{N}}, b_1, \\cdots, b_{\\tilde{N}}, \\mathrm{x}_1, \\cdots, \\mathrm{x}_N)=\\begin{aligned}\\begin{bmatrix}g(\\mathrm{w}_1\\cdot \\mathrm{x}_1 + b_1) &amp;amp; \\cdots &amp;amp; g(\\mathrm{w}_{\\tilde{N}}\\cdot \\mathrm{x}_1 + b_{\\tilde{N}}) \\\\\\vdots &amp;amp; \\cdots &amp;amp; \\vdots \\\\g(\\mathrm{w}_1\\cdot \\mathrm{x}_N + b_1) &amp;amp; \\cdots &amp;amp; g(\\mathrm{w}_{\\tilde{N}}\\cdot \\mathrm{x}_N + b_{\\tilde{N}})\\end{bmatrix}\\end{aligned}_{N\\times \\tilde{N}}\\]\\[\\beta =\\begin{aligned}\\begin{bmatrix}\\beta_1^\\intercal \\\\\\vdots \\\\\\beta_{\\tilde{N}}^\\intercal\\end{bmatrix}\\end{aligned}_{\\tilde{N} \\times m}\\]\\[T =\\begin{aligned}\\begin{bmatrix}t_1^\\intercal \\\\\\vdots \\\\t_{\\tilde{N}}^\\intercal\\end{bmatrix}\\end{aligned}_{N \\times m}\\]Ta có thể thấy công thức \\(\\mathrm{H}\\beta = \\mathrm{T}\\) giống hệt hệ phương trình với biến là $\\beta$. Vì thế, ta có thể giải và tìm $\\beta$ theo công thức:\\[\\hat{\\beta} = \\mathrm{H}^\\dagger\\mathrm{T}\\]Trong đó, $\\hat{\\beta}$ là nghiệm $\\beta$ tối ưu, kí hiệu $\\dagger$ (dagger) đại diện cho phép nghịch đảo ma trận theo phương pháp Moore-Penrose, bạn đọc có thể tìm hiểu thêm ở đây. Lúc này, nghiệm của bài toán sẽ là duy nhất, vì nghiệm của phương pháp nghịch đảo ma trận Moore-Penrose là duy nhất.Vấn đề là còn lại $\\mathrm{W}$ và $\\mathrm{b}$ chưa có lời giải. Nhưng thực ra, theo nghiên cứu [1], tác giả Guang-Bin Huang và đồng nghiệp đã chứng minh một cách chặt chẽ rằng: Bài toán luôn luôn có nghiệm mặc dù $\\mathrm{W}$ và $\\mathrm{b}$ có thể được chọn ngẫu nhiên như thế nào đi chăng nữa. Nên vấn đề của $\\mathrm{W}$ và $\\mathrm{b}$ đã được giải quyết.Vì thế, nhóm tác giả đã trình bày thuật toán Extreme Learning Machine (có thể gọi là ELM) gồm các bước sau: Bước 1: Ngẫu nhiên chọn giá trị cho $\\mathrm{w}_i$ và $\\mathrm{b}_i$ với $i=1,\\cdots, \\tilde{N}$. Bước 2: Tính giá trị của ma trận trọng số kết nối đầu vào và lớp ẩn $H$. Bước 3: Tính giá trị của ma trận trọng số kết nối lớp ẩn và đầu ra $\\beta$.Điểm đặc biệt của thuật toán này là học rất nhanh, do đây là thuật toán huấn luyện không lặp, cải thiện thời gian rất nhiều, không giống như phương pháp gradient-descent, là thuật toán tối ưu lặp.Đối với các bài toán khác nhau, sẽ có cách chọn $g(x)$ khác nhau. Có thể chọn giữa các hàm như: linear activation, relu, sigmoid, softmax, tanh, v.v.Trong bài toán Regression, đầu ra có thể là hàm tuyến tính (linear activation), nghĩa là không cần hàm kích hoạt. Còn trong bài toán Classification, hàm kích hoạt đầu ra có thể dùng là hàm sigmoid đối với bài toán phân lớp nhị phân, hoặc softmax nếu là phân lớp đa lớp. Lúc này, ký hiệu hàm kích hoạt đầu ra là \\(\\sigma(\\mathrm{o}_j)\\), trong đó $\\sigma$ có thể là các hàm linear activation, sigmoid hoặc softmax như đã đề cập.3. Thực nghiệm thuật toán Extreme Learning Machine với hai bài toán: Regression và ClassificationDo thuật toán ELM thực chất cũng khá đơn giản, nên ta có thể thực hiện trực tiếp với Python và thư viện Numpy. Dưới đây là đoạn code tham khảo về việc hiện thực thuật toán ELM cho hai bài toán Regression và Classification, với lớp ELMRegressor đại diện cho bài toán Regression, và lớp ELMClassifier đại diện cho bài toán Classification.Gọi $X$ là ma trận dữ liệu đầu vào, $y$ là vector dữ liệu đầu ra, lúc này $y$ có thể thay thế cho $T$ đối với mạng neuron một lớp ẩn.import numpy as npfrom sklearn.preprocessing import OneHotEncoderfrom scipy.special import softmaxfrom utils import relu, sigmoid, linearclass ELMBase: def __init__(self, n_hiddens=128, random_state=12, activation=linear): self.n_hiddens = n_hiddens self.rs = np.random.RandomState(random_state) self.activation = activation class ELMRegressor(ELMBase): def __init__(self, n_hiddens=128, random_state=12): ELMBase.__init__(self, n_hiddens, random_state, linear) def fit(self, X, y): self.W = self.rs.normal(size=(X.shape[1], self.n_hiddens)) self.b = self.rs.normal(size=(self.n_hiddens)) y = y.reshape(-1, 1) H = self.activation(X.dot(self.W) + self.b) self.Beta = np.linalg.pinv(H).dot(y) return self def predict(self, X): H = self.activation(X.dot(self.W) + self.b) dot_product = H.dot(self.Beta) return dot_product class ELMClassifier(ELMBase): def __init__(self, n_hiddens=128, random_state=12): ELMBase.__init__(self, n_hiddens, random_state, relu) self.output_activation = softmax self.encoder = OneHotEncoder() def fit(self, X, y): self.W = self.rs.normal(size=(X.shape[1], self.n_hiddens)) self.b = self.rs.normal(size=(self.n_hiddens)) y = self.encoder.fit_transform(y.reshape(-1, 1)).toarray() H = self.activation(X.dot(self.W) + self.b) self.Beta = np.linalg.pinv(H).dot(y) return self def predict(self, X): return np.argmax(self.predict_proba(X), axis=1) def predict_proba(self, X): H = self.activation(X.dot(self.W) + self.b) dot_product = H.dot(self.Beta) return self.output_activation(dot_product)Sau khi đã hiện thực được thuật toán, ta có thể đi so sánh kết quả (thời gian và độ chính xác) với các thuật toán khác, trong bài viết này, tôi sử dụng các dạng mô hình tuyến tính (linear model) như Ridge và Logistic Regression, mô hình dạng Support Vector Machine (SVM), mô hình K-Nearest Neighbors (KNN), dạng mô hình cây Decision Tree, mô hình cây kết hợp Random Forest và mô hình Perceptron 1 lớp ẩn (được huấn luyện bằng back-propagation).Kết quả sẽ được so sánh trên hai bộ dữ liệu: Boston Housing cho bài toán và MNIST cho bài toán . Mà thang đo cho bài toán sẽ là Root Mean Square Error (căn bậc hai bình phương trung bình sai số) và accuracy (độ chính xác) đối với bài toán .3.1 Kết quả so sánhMạng neuron một lớp ẩn và Perceptron sẽ có số lượng node ở lớp ẩn là $500$, các tham số của các mô hình khác đều được giữ mặc định.Kết quả trên bộ dữ liệu Boston Housing Thuật toán Loại Thời gian huấn luyện (mili giây) RMSE trên tập huấn luyện RMSE trên tập kiểm thử ELM Neural Network 54.62 4.69 4.82 Ridge Linear Model 2.66 4.72 4.75 SVR Support Vector Machine 26.32 8.25 8.15 K-Nearest Neighbors Nearest Neighbors 1.97 4.98 6.08 Decision Tree Tree-based 7.2 0 5.1 Random Forest Tree-based Ensemble 293.13 1.19 3.8 Perceptron (Back-propagation) Neural Network 237.5 6.94 7.43 Kết quả trên bộ dữ liệu MNIST Thuật toán Loại Thời gian huấn luyện (mili giây) Độ chính xác trên tập huấn luyện (%) Độ chính xác trên tập kiểm thử (%) ELM Neural Network 4754.13 91.94 92.22 Logistic Linear Model 21112.03 93.39 92.55 SVC Support Vector Machine 280275.89 98.99 97.92 K-Nearest Neighbors Nearest Neighbors 5.07 98.19 96.88 Decision Tree Tree-based 17913.2 100.0 87.68 Random Forest Tree-based Ensemble 37244.7 100.0 96.95 Perceptron (Back-propagation) Neural Network 379703.05 99.73 97.85 Bạn đọc có thể tham khảo toàn bộ code hiện thực trong bài viết này ở đây.4. Tổng kếtQua bài viết này, tôi đã trình bày về cấu trúc của mô hình mạng neuron truyển thẳng một lớp ẩn (SLFN) và vấn đề bất cập trong việc tìm các trọng số của mô hình với thuật toán back-propagation. Từ đó nêu lên thuật toán Extreme Learning Machine giúp giải quyết vấn đề học một cách nhanh và tối ưu. Kết quả thực nghiệm trong phần 3.1 cho thấy rằng tốc độ học của Extreme Learning Machine nhanh hơn hẳn so với back-propagation (mô hình Perceptron), tuy nhiên khi so sánh với các thuật toán đơn giản hơn nhiều như K-Nearest Neighbors thì chưa nhanh bằng, dù gì thì ELM cũng là một mạng neuron nên cấu trúc sẽ phức tạp hơn.5. Tham khảo[1] Guang-Bin Huang, Qin-Yu Zhu, Chee-Kheong Siew, Extreme learning machine: Theory and applications, 2006. https://doi.org/10.1016/j.neucom.2005.12.126." }, { "title": "Mô hình Markov ẩn và bài toán phân tích cảm xúc văn bản", "url": "/posts/hidden-markov-model-and-sentiment-analysis/", "categories": "knowledge", "tags": "machine learning, probability, nlp, sentiment analysis, hmm, markov process", "date": "2022-01-03 20:51:00 +0700", "snippet": "Nội dung 1. Định nghĩa 2. Ba bài toán nền tảng 3. Bài toán phân tích cảm xúc văn bản 3.1 Giới thiệu bài toán phân tích cảm xúc văn bản 3.2 Bộ dữ liệu Financial News của Kaggle 3.3 Mô hình bài toán 3.4 Phương pháp thực hiện 4. Tổng kết 5. Tham khảo1. Định nghĩaỞ bài viết về Markov chain, chúng ta đã tìm hiểu về một mô hình được kết hợp bởi các trạng thái, các trạng thái cũng đồng thời cũng là kết quả của mô hình. Trong bài viết này, chúng ta sẽ tìm hiểu về mô hình Markov ẩn (Hidden Markov model - HMM), mà các trạng thái của mô hình lúc này sẽ không phải là thứ chúng ta có thể quan sát được.Mô hình Markov ẩn là một mô hình thống kê được kết hợp bởi tập các trạng thái ẩn (hidden state) và tập các quan sát (observation). Mô hình Markov ẩn sử dụng tính chất Markov giống Markov chain, trạng thái hiện tại chỉ phụ thuộc vào trạng thái trước đó, ngoài ra các quan sát hiện tại chỉ phụ thuộc vào trạng thái hiện tại.Mô hình Markov ẩn từng thống trị rất nhiều bài toán và lĩnh vực ở thập kỷ trước (chứng cứ là có rất nhiều bài báo được đăng tải liên quan đến mô hình Markov ẩn liên quan đến nhiều lĩnh vực tại thời điểm đó), nhất là trong lĩnh vực Nhận dạng giọng nói (Speech Recognition). Trong lĩnh vực nhận dạng giọng nói, mô hình Markov ẩn đóng vai trò như một mô hình âm học đại diện cho một đơn vị nhận dạng giọng nói.Mô hình Markov ẩn được kết hợp bởi 5 thành phần, ta có thể gọi một mô hình Markov ẩn là $\\lambda =(Q, V, A, B, \\pi)$ (có thể đơn giản hóa ký hiệu thành $\\lambda =(A, B, \\pi)$), trong đó: $Q=q_1, q_2, \\cdots, q_N$ là tập gồm $N$ trạng thái ẩn, $X_t \\in Q$ là giá trị ở thời điểm $t$ được lấy trong tập $Q$. $O=o_1, o_2, \\cdots, o_T$ là một chuỗi gồm $T$ (là thời điểm cuối cùng) quan sát, mỗi quan sát được lấy từ tập giá trị duy nhất $V = \\{v_1, v_2, \\cdots, v_V\\}$. $A_{N\\times N}$ là ma trận xác suất chuyển, được ký hiệu là $A=a_{ij}=\\{P(X_{t+1} = q_j|X_t = q_i)|1 \\le i,j \\le N\\}$. Ở đây, $a_{ij}$ đại diện cho xác suất chuyển từ trạng thái $i$ ở thời điểm $t$ sang trạng thái $j$ ở thời điểm $t+1$ $B_{V\\times N}$ là ma trận xác suất phát xạ (emission probability), và được ký hiệu bởi $B=b_i(k)=\\{P(O_t = v_k|X_t=Q_i)|1\\le i\\le N, 1 \\le k \\le V\\}$. $b_i(k)$ đại diện cho xác suất ký hiệu $v_k$ được phát xạ ra từ trạng thái $i$ tại thời điểm $t$. $\\pi=\\pi_i=\\{P(X_1=S_i)|1\\le i \\le n\\}$ là tập xác suất khởi tạo trạng thái.Hình 2 mô tả trừu tượng cấu trúc của mô hình Markov ẩn được đề cập ở trên. Hình $(a)$ là sơ đồ gồm các tập trạng thái ẩn $q_i$ và các giá trị xác suất chuyển $a_{ij}$, trông giống hệt như một Markov chain. Hình $(b)$ mô tả: với mỗi trạng thái ẩn $q_i$, sẽ có một tập giá trị $v_k$ là tập giá trị sẽ được xuất ra với xác suất $b_i(k)$ tương ứng, và hình $(b)$ là điều khiến mô hình Markov ẩn khác với Markov chain. Hình 1: Dạng và cấu tạo của mô hình Markov ẩn trừu tượngHình dưới đây mô tả một dạng hiện thực của mô hình Markov ẩn, với $X_t \\in Q$ và $O_t \\in V$. Ta có một dạng của mô hình Markov ẩn theo thời gian thực. Dạng $\\cdots$ (ba chấm) ở đây biểu thị các trạng thái trước đó và trạng thái tương lai cách thời điểm $t$ hơn $1$ đơn vị. Theo tính chất Markov, trạng thái hiện tại chỉ phụ thuộc vào trạng thái từ quá khứ cách nó một đơn vị, và trạng thái tương lai cũng chỉ phụ thuộc vào trạng thái hiện tại. Theo công thức toán học có thể mô tả là:\\(P(X_t|X_{t-1}, X_{t-2}, X_{t-3}, \\cdots)=P(X_t|X_{t-1})\\). Hình 2: Một dạng hiện thực của mô hình Markov ẩnDo có cấu tạo như hình 2, mô hình Markov ẩn rất thích hợp trong những bài toán mô hình hóa chuỗi các giá trị. Trong thực tế, ta có thể xem các chuỗi giá trị là dữ liệu chúng ta có được từ thực tế và phân phối để lấy ra chuỗi giá trị kia ta không hề biết trước. Trong trường hợp này, ta có thể dùng mô hình Markov ẩn để mô hình hóa chuỗi giá trị đó để có được tập các trạng thái ẩn và phân phối xác suất thích hợp, cách để học và lấy ra các trạng thái ẩn sẽ được trình bày trong phần 2.Phần tiếp theo, phần 2 sẽ giới thiệu ba bài toán nền tảng của mô hình Markov ẩn, tuy nền tảng nhưng là nền móng cho mọi bài toán phức tạp hơn trong thế giới thực chiến.2. Ba bài toán nền tảngỞ phần 1, tôi đã đi sơ lược về cấu tạo, cấu trúc và các thành phần đằng sau mô hình Markov ẩn. Đến thời điểm này, chắc hẳn bạn đọc sẽ thắc mắc cách sử dụng mô hình Markov ẩn như thế nào, vì thực tế, mô hình Markov ẩn có một cấu trúc dạng chuỗi tuần tự đặc biệt, trông rất khác so với các mô hình truyền thống như Linear Regression, Logistic Regression, Random Forest, … .Vì thế, mô hình Markov ẩn cũng sẽ có những cách sử dụng khác. Cụ thể hơn, để sử dụng mô hình Markov ẩn, ta bắt buộc phải giải quyết được 3 bài toán được mô tả dưới đây. Ba bài toán đó là: Bài toán 1: Đưa trước chuỗi quan sát $O=o_1, o_2, \\cdots, o_T$ và mô hình $\\lambda = (A, B, \\pi)$. Làm cách nào để ta có thể tính hiệu quả$P(O|\\lambda)$, chính là xác suất để chuỗi quan sát xảy ra khi biết trước mô hình? Bài toán 2: Đưa trước chuỗi quan sát $O=o_1, o_2, \\cdots, o_T$ và mô hình $\\lambda = (A, B, \\pi)$. Làm cách nào để ta có thể tìm được một chuỗi trạng thái ẩn $X=X_1, X_2, \\cdots, X_T$ để giải thích tốt nhất cho chuỗi quan sát $O$? Bài toán 3: Làm cách nào để ta có thể điều chỉnh tham số của mô hình $\\lambda = (A, B, \\pi)$ để tối đa hóa xác suất $P(O|\\lambda)$?Bài toán 1 là bài toán đánh giá (evaluation problem), nghĩa là đi tính xác suất xảy ra của một chuỗi quan sát khi ta có được mô hình. Nếu nhìn ở một khía cạnh khác, đây chính là bài toán chấm điểm mô hình, nếu mô hình nào có xác suất $P(O|\\lambda)$ cao hơn nghĩa là mô hình đó tốt hơn. Bài toán 2 là bài toán giải mã (decoding problem), có thể hiểu là ta đã có một chuỗi quan sát $O$ và ta có thể thấy, bây giờ ta phải tìm một chuỗi trạng thái ẩn tương ứng (có cùng kích cỡ) $X$ sao cho giải thích tốt nhất chuỗi quan sát $O$ kia. Bài toán 3 là bài toán học (learning problem), là bài toán quan trọng nhất. Vì nhờ bài toán 3, ta có thể tối ưu hóa các tham số của mô hình Markov ẩn $\\lambda$ đến mức hội tụ, sử dụng cho nhiều bài toán thực tế khác nhau.Cả ba bài toán trên đều có cách giải rất đơn giản, đó là thế vào và thử, tuy nhiên độ phức tạp tính toán sẽ rất cao, nên người ta dùng kỹ thuật quy hoạch động (dynamic programming) để tối ưu, giúp giải quyết cả 3 vấn đề một cách quy nạp và theo độ phức tạp đa thức. Cụ thể bài toán 1 có thể giải với thuật toán forward-backward, bài toán 2 sẽ giải bằng thuật toán Viterbi và bài toán 3 sẽ giải bằng thuật toán Baum-Welch.Trong phần này, tôi chỉ đi giới thiệu về ba bài toán, về cách giải sẽ không được đề cập đến, bạn đọc có hứng thú với lời giải cho ba bài toán có thể tham khảo [3], đây là bài báo rất chất lượng về mô hình Markov ẩn, là nền tảng cho bất cứ ai mới bắt đầu tìm hiểu về mô hình Markov ẩn. Nếu gặp khó khăn trong việc hiện thực thuật toán, bạn đọc có thể tham khảo đến github của tôi, tôi cũng đã đọc bài báo số [3] và hiện thực thành công.3. Bài toán phân tích cảm xúc văn bản3.1 Giới thiệu bài toán phân tích cảm xúc văn bảnPhân tích cảm xúc văn bản (sentiment analysis) là bài toán được nghiên cứu trong lĩnh vực Xử lý ngôn ngữ tự nhiên. Mục tiêu của bài toán là tìm ra cảm xúc (tích cực, tiêu cực, trung tính) của một câu chữ trong một lĩnh vực cụ thể nào đó. Bài toán này rất được ưa chuộng trong các công ty mà lượng dữ liệu về chữ của họ lớn, họ có thể khai thác thông tin từ nguồn dữ liệu của họ, từ đó hiểu được khách hàng của họ cần gì. Ví dụ như các bình luận trên shopee hay tiki là một ví dụ, một câu “Tôi rất thích sản phẩm này” sẽ được đánh nhãn là tích cực, câu “Sản phẩm này nhăn nheo quá” sẽ được gán nhãn là tiêu cực, một trường hợp khác có nhãn là trung tính, không rõ ràng tích cực hay tiêu cực, ví dụ như câu “Hôm nay tôi vừa nhận được sản phẩm này”.Hiện tại, bài toán này có thể giải quyết bằng những phương pháp Machine Learning hoặc mạnh hơn là Deep Learning, chi tiết bạn đọc có thể tìm hiểu ở đây. Nhưng trong phạm vi bài viết này, chúng ta sẽ tiếp cận với một hướng khác, đó là giải quyết bài toán này bằng mô hình Markov ẩn.3.2 Bộ dữ liệu Financial News của KaggleBộ dữ liệu chúng ta sẽ đi nghiên cứu là bộ Financial News được lấy trên Kaggle. Dữ liệu gồm 2 cột, 4837 hàng, cột thứ nhất là nhãn, tức là cảm xúc của văn bản đã được gắn từ trước, gồm 3 giá trị: positive, neutral, negative. Cột thứ hai là văn bản. Dữ liệu này đầy đủ và đơn giản để sử dụng trong bài toán này.3.3 Mô hình bài toánKhi ứng dụng mô hình Markov ẩn vào bài toán phân lớp (classification) như chúng ta đang định làm, chúng ta phải mô hình hóa một số lượng mô hình Markov ẩn riêng biệt bằng với số lượng lớp của bài toán. Nếu lấy bộ dữ liệu Financial News kia làm chuẩn, ta sẽ có 3 mô hình Markov ẩn tương ứng với 3 lớp positive, neutral và negative.Mô hình Markov ẩn sẽ làm tốt công việc của mình trong việc mô hình hóa phân phối xác suất của riêng từng lớp. Nếu coi tập dữ liệu là $O$ và có tổng cộng 3 mô hình Markov ẩn tương ứng với 3 lớp thì lớp dự đoán khi ta đưa dữ liệu mới vào sẽ theo công thức dưới đây:\\[C^\\star = \\underset{C}{\\mathrm{argmax }} P(O|\\lambda_C)\\]Trong đó: $C$ là lớp (nhãn) và $C^\\star$ là lớp dự đoán. $\\lambda_C$ là mô hình Markov ẩn tương ứng với mỗi lớp. $P(O|\\lambda_C)$chính là bài toán 1, bài toán đánh giá mô hình.Bất cứ mô hình Machine Learning nào cũng sẽ có giai đoạn huấn luyện, mô hình Markov ẩn cũng không ngoại lệ. Hình (3a) mô tả quy trình này, ban đầu ta có một tập dữ liệu $O$ (có thể là nhiều $O$) và $n$ lớp (nhãn) tương ứng. Ta sẽ chia tập dữ liệu ra thành $n$ tập dữ liệu nhỏ hơn tương ứng với $n$ nhãn. Sau đó dùng thuật toán Baum-Welch (bài toán số 3) để huấn luyện cho mô hình $\\lambda_{C_i}$ tương ứng. Kết thúc quá trình huấn luyện, ta được $n$ mô hình Markov ẩn tương ứng với $n$ nhãn lớp.Để có thể sử dụng $n$ mô hình kia trong quá trình kiểm thử hoặc đi dự đoán. Ta cần đưa dữ liệu kiểm thử cho cả $n$ mô hình Markov ẩn, sau đó đi tìm các xác suất $P(O|\\lambda_{C_i})$ (bài toán số 1) và chọn nhãn $C$ có giá trị xác suất lớn nhất, nhãn $C$ này sẽ là nhãn dự đoán cho chuỗi quan sát $O$ ta đưa vào. Hình (3b) mô tả rõ quy trình này. Hình 3: Sơ đồ của mô hình Markov ẩn (a) trong quá trình huấn luyện và (b) trong quá trình kiểm thử3.4 Phương pháp thực hiệnBây giờ chúng ta sẽ đi đến phần hiện thực bài toán, tôi sẽ sử dụng ngôn ngữ lập trình Python với các thư viện ở ô code dưới đây.⚠️ Lưu ý: khi code báo lỗi thư viện, các bạn có thể tự cài thư viện thông qua pip install {tên thư viện}.import numpy as np # thư viện tính toán import pandas as pd # đọc file csvimport concurrent.futures as cf # thư viện giúp code python chạy đa luồngfrom hmmlearn import hmm # thư viện mô hình Markov ẩn from sklearn.cluster import KMeans # lượng hóa vectorfrom sklearn.metrics import accuracy_score # đo độ chính xác của mô hìnhfrom sklearn.decomposition import TruncatedSVD # giảm chiều dữ liệufrom sklearn.model_selection import train_test_split # chia tập dữ liệu train|testfrom sklearn.feature_extraction.text import TfidfVectorizer # tạo feature cho mô hình từ chữ👉 Chúng ta sẽ đi qua các bước như sau: Tạo feature dữ liệu số từ dữ liệu chữ có sẵn bằng TF-IDF. Lượng hóa vector (vector quantization) dữ liệu số liên tục thành dạng định tính có thể đem đi huấn luyện. Chia tập dữ liệu huấn luyện, kiểm thử tương ứng. Huấn luyện bộ mô hình Markov ẩn với tập dữ liệu huấn luyện. Đánh giá mô hình Markov ẩn thông qua tập dữ liệu kiểm thử.Trước tiên, ta sẽ đọc dữ liệu để có thể chuẩn bị cho bước tạo feature cho mô hình. Dữ liệu đã được đề cập trong phần 3.2.df = pd.read_csv(&#39;all-data.csv&#39;, encoding=&quot;ISO-8859-1&quot;, header=None, names=[&#39;label&#39;, &#39;text&#39;])Để trạng thái của code không thay đổi qua mỗi lần chạy, ta nên gán cụ thể giá trị random state cho các thư viện. Dưới đây tôi định nghĩa biến rs là giá trị random state để dùng cho các code sau. Giá trị các bạn có thể thay đổi bất kỳ.rs = 8Tạo biến corpus để gán dữ liệu chữ vào, tiện sử dụng về sau.corpus = df[&#39;text&#39;].valuesNhư các mô hình Machine Learning truyền thống khác, mô hình Markov ẩn sẽ chỉ làm việc được với các giá trị số. Mà dữ liệu ban đầu của chúng ta là dữ liệu dạng chữ, nên ta phải chuyển từ chữ sang số. Để làm như vậy, ta sử dụng TF-IDF để tính toán các giá trị trọng số để đại diện cho từng từ một trong bộ ngữ liệu ban đầu. Chi tiết hơn về TF-IDF, bạn đọc có thể tham khảo ở đây. Còn trong Python, ta sẽ tính bằng đoạn code sau:tfidf = TfidfVectorizer(stop_words=&#39;english&#39;)transformed = tfidf.fit_transform(corpus)print(&quot;Kích cỡ dữ liệu:&quot;, transformed.shape)Kích cỡ dữ liệu: (4846, 9820)Như bạn đọc cũng đã thấy, có tận 9820 cột dữ liệu được tạo ra, như vậy là quá nhiều, ta phải dùng cách nào đó để giữ lại các thông tin quan trọng nhất, giảm bớt số lượng cột lại, nhờ đó giúp giảm thời gian huấn luyện và kiểm thử, mô hình cũng không phải học những thông tin dư thừa. Trong trường hợp này, ta sẽ dùng Truncated SVD với số lượng cột ta muốn giữ lại là 300. Chi tiết về Truncated SVD, bạn đọc có thể tham khảo ở blog machine learning cơ bản.svd = TruncatedSVD(n_components=300, random_state=rs)X_transformed = svd.fit_transform(transformed)print(&quot;Kích cỡ dữ liệu:&quot;, X_transformed.shape)print(X_transformed)Kích cỡ dữ liệu: (4846, 300)[[ 2.74853772e-02 1.23546023e-01 -9.18267054e-02 ... -1.04585446e-02 6.31456379e-02 1.64352977e-02] [ 1.71779475e-02 6.60849287e-02 -3.16730100e-02 ... 3.16069539e-02 2.32036018e-02 -8.03645790e-03] [ 2.53099565e-02 8.71819162e-02 -5.00550792e-02 ... -5.08493999e-02 -6.52592321e-02 -4.16690704e-02] ... [ 6.29146372e-01 -1.92710754e-01 3.24730118e-02 ... 3.28086253e-02 -1.07719957e-02 -8.53337727e-04] [ 6.66497950e-01 -1.41546038e-01 1.81541966e-03 ... 7.96125651e-03 -2.97791037e-03 -1.60182069e-04] [ 9.54134895e-02 1.71111951e-01 -6.08651229e-02 ... -1.30032385e-02 3.79181183e-02 1.24508153e-02]]Ngoài vấn đề có quá nhiều cột trong feature đã được giải quyết, ta còn gặp thêm một vấn đề nữa đó là dữ liệu không phù hợp với mô hình Markov ẩn. Như đã tìm hiểu trên phần 1, các quan sát $O$ của mô hình Markov ẩn được lấy từ một tập $V$ phần tử, vì thế, dữ liệu đưa vào cho mô hình Markov ẩn phải là dạng định tính.Để giải quyết vấn đề trên, ta có thể dùng một kỹ thuật được gọi là lượng hóa vector (vector quantization). Lượng hóa vector có thể hiểu đơn giản là phân cụm các giá trị liên tục thành một tập các cụm có sự giống nhau. Chỉ số của các cụm bây giờ có thể coi như là các giá trị được lấy trong tập $V = \\text{số cụm}$ phần tử. Giá trị trong cùng một tập sẽ có cùng một chỉ số này. Ở phần hiện thực, tôi sẽ đi lượng hóa vector bằng thuật toán K-Means với số cụm là 30.X_cluster = X_transformed.reshape(-1, 1) vq = KMeans(n_clusters=30) # vector quantizationvq.fit(X_cluster)def map_vq(x): return vq.predict(x.reshape(-1, 1))with cf.ThreadPoolExecutor() as exe: X = np.array(list(exe.map(map_vq, X_transformed)))print(X)[[ 9 11 0 ... 8 16 22] [27 16 20 ... 9 27 8] [ 9 3 19 ... 19 28 10] ... [26 24 4 ... 4 8 13] [26 24 13 ... 1 29 13] [ 3 18 28 ... 17 4 22]]Như bạn có thể thấy, dữ liệu định lượng được lấy ra từ TF-IDF đã chuyển thành dạng số nguyên, là chỉ số của các cụm. Bây giờ, ta sẽ đi phân chia dữ liệu thành hai tập: huấn luyện và kiểm thử với tỉ lệ 8:2.y = df[&#39;label&#39;]Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, random_state=rs)Sau khi đã có dữ liệu, ta sẽ đi tạo mô hình Markov ẩn cho bài toán này rồi mới huấn luyện. Ta sẽ tạo cấu trúc mô hình giống như hình 3.class HMMSystem: def __init__(self, n_components=10, random_state=rs): self.n_components = n_components self.random_state = random_state def fit(self, X, y): self.labels = np.unique(y) self.X = X self.y = y self.hmm_models = {} for c in self.labels: with cf.ThreadPoolExecutor() as exe: self.hmm_models = list(exe.map(self._create_model, self.labels)) self.hmm_models = dict(zip(self.labels, self.hmm_models)) return self def predict(self, X): with cf.ThreadPoolExecutor() as exe: pred = np.array(list(exe.map(self._find_class, X))) return pred def _create_model(self, label): model = hmm.MultinomialHMM( n_components=self.n_components, random_state=self.random_state ).fit(self.X[self.y == label]) return model def _find_class(self, data): def _decode(model): return model.decode([data])[0] with cf.ThreadPoolExecutor() as exe: logprobs = list(exe.map(_decode, self.hmm_models.values())) return self.labels[np.argmax(logprobs)]Huấn luyện mô hình với tập dữ liệu huấn luyện. Ta sẽ chọn số lượng trạng thái ẩn $Q$ là 8.⚠️ Lưu ý: quá trình huấn luyện có thể hơi lâu, khoảng vài phút.model = HMMSystem(8, rs)model.fit(X, y)Dùng tập kiểm thử để dự đoán với mô hình đã huấn luyện.ytest_pred = model.predict(Xtest)ytrain_pred = model.predict(Xtrain)Cuối cùng là đi đánh giá trên cả hai tập dữ liệu đã dự đoán.acc_train = accuracy_score(ytrain, ytrain_pred)acc_test = accuracy_score(ytest, ytest_pred)print(&quot;Độ chính xác tập huấn luyện: %.2f/1&quot; % acc_train)print(&quot;Độ chính xác tập kiểm thử: %.2f/1&quot; % acc_test)Độ chính xác tập huấn luyện: 0.46/1Độ chính xác tập kiểm thử: 0.48/1Độ chính xác của mô hình là $48\\%$ trên tập kiểm thử, mức độ chính xác này vào khoảng giữa, 50:50, nên kết quả dự đoán của mô hình còn khá rủi ro.Toàn bộ code Python hiện thực sẽ để ở đây.4. Tổng kếtTrong bài viết này, chúng ta đã đi qua sơ lược về định nghĩa, các thành phần và các bài toán của mô hình Markov ẩn. Từ đó ứng dụng mô hình Markov ẩn vào bài toán phân tích cảm xúc văn bản. Độ chính xác của mô hình không quá cao, nhưng nó giúp bạn đọc có thể hiểu thêm về mô hình này. Bạn đọc có thể đọc thêm về mô hình Markov ẩn ở các bài báo và địa chỉ website trong phần 5.5. Tham khảo[1] https://web.stanford.edu/~jurafsky/slp3/A.pdf[2] https://en.wikipedia.org/wiki/Hidden_Markov_model[3] A Tutorial on Hidden Markov Models and Selected Applications in Speech Recognition. Rabiner. 1989.[4] A Systematic Review of Hidden Markov Models and Their Applications. Bhavya Mor, Sunita Garhwal &amp;amp; Ajay Kumar. 2021.[5] Hidden Markov Models for Sentiment Analysis in Social Medias. Isidoros Perikos. 2019." }, { "title": "Mình đã học được gì trong năm nay?", "url": "/posts/minh-da-hoc-duoc-ghi-trong-nam-nay/", "categories": "share", "tags": "think", "date": "2021-12-31 00:34:00 +0700", "snippet": "“Mình đã học được những gì trong năm nay?” 🧐Phải thú thật rằng, câu hỏi trên chỉ mới xuất hiện trong đầu mình mươi phút trước, nhưng nó khiến mình thao thức không ngủ được mà đành phải viết ra suy nghĩ của chính bản thân.Năm vừa rồi đúng là một năm tàn ác, khi covid xuất hiện và cướp đi bao nhiêu thứ trong cuộc sống của mỗi cá nhân. Nhưng đó cũng là một năm đầy cơ hội, khi mỗi người đều có nhiều thời gian hơn để làm việc họ muốn, để phát triển bản thân họ. Và đối với mình, đó vừa là năm tàn ác, cũng là năm cơ hội.Mình bắt đầu năm này với dự án Vis For Teacher, cùng với thầy và hai người bạn của mình, chúng mình tâm huyết, bỏ thời gian vào, hăng say và đam mê với nó, nguyện thức xuyên đêm chỉ để bàn về hướng đi tiếp theo và phát triển tiếp. CV lúc này đã có thêm mấy chữ, toàn là những gì đã học và đạt được trong dự án. Cách đây 2 tháng, dự án đậu vào top 5 của cuộc thi khởi nghiệp của trường, nhưng để phát triển tiếp, cần phải rẽ sang một hướng khác mà nhóm của mình không mấy quan tâm lắm. Chúng mình bỏ qua một bên, để tập trung vào việc học chính. Tuy không đi quá xa, nhưng kĩ năng làm việc nhóm, cách giao tiếp đội nhóm, cách tạo động lực cho nhau, các kiến thức kỹ thuật đã đạt được thì đúng là vô giá. Cảm ơn thầy và hai bạn đã cho mình cơ hội học tập tuyệt vời này.Vào khoảng tháng 4, tháng 5 gì đó, tay code và khả năng nghiên cứu còn hạn chế. Nhưng thầy vẫn nhận đơn cho nhóm đăng ký hackathon của trường đại học khác, lúc đấy cũng cùng với hai bạn khác, hai bạn cũng non giống mình, cũng chỉ học trên trường lớp chứ chưa đi thi thố với ai. Ấy thế mà sau cuộc thi, nhóm mình may mắn được giải nhì, cũng không to lắm, nhưng đúng là rất khích lệ bản thân. CV lại có thêm mấy chữ, có thêm mấy gạch đầu dòng về những kiến thức đã học sau khi tham gia cuộc thi. Lại thêm một cơ hội tuyệt vời để học.Hồi hè, nhóm mình có 5 người, sẵn lúc đó đang nghỉ dịch, nhóm liền đề xuất với thầy tạo một sân chơi học tập, đúng là vừa học vừa chơi, tên là Problem Based Learning, dựa trên format của anh chị mentor vào năm trước đó. Sân chơi diễn ra liên tục trong 5 tuần liền, 5 tuần bọn mình cứ họp suốt, cứ tối cái là vô họp bàn kế hoạch, nội dung, kiến thức để triển khai cho chiều chủ nhật để “dạy” lại cho các bạn khác. Vào tuần cuối, nhóm 5 bọn mình cứ ngồi nghe các nhóm tham gia sân chơi báo cáo, có được biết bao nhiêu kiến thức hay, họ tham gia để chơi, nhưng họ học thật, họ học dữ nữa là đằng khác. Mình và nhóm của mình cứ ngồi ung dung hưởng thụ kiến thức, lại còn mở rộng các mối quan hệ bạn bè, mình còn quen biết được một anh học trường khác, chắc chăm nhất sân chơi. Đúng là cơ hội học tập tuyệt vời nhất đó chính là dạy lại kiến thức mình đã có cho người khác, để họ có thể dạy lại cho ta những gì họ biết 😊Lần đầu tiên mình đi thực tập cũng chính là vào khoảng thời gian đó, lúc hè thì thời gian nhiều, không có sao. Nhưng đến khi vô học, tháng 9, tháng 10 gì đấy, mình lần đầu biết đến khái niệm “burn out”, có thể dịch là quá tải. Mình đã bị quá tải, phải nói lúc đó, mình không hề biết cách sắp xếp thời gian đâu cho vừa, vì cái thói thích gì làm nấy, gì cũng nhận, nên đâm ra việc thừa thãi thì làm nhiều, việc quan trọng thì làm ít. Đợt đó suy nghĩ dữ lắm, sao cứ hết ngày là mình đuối dữ. Mình may mắn xem được các video sắp xếp thời gian, rồi tự mày mò sắp xếp thời gian trên lịch của Google Calendar. Sau 1 tháng làm theo lịch, đỡ hẳn, thoải mái hơn nhiều, mình có thể làm hết những việc quan trọng, lại còn có thời gian hưởng thụ đọc sách. Đúng là chỉ có những lúc như thế, ta mới học được cách quản lý thời gian sao cho đúng nhất thôi. Mình lại học được thêm thứ nữa.Đợt đáng nói nhất là gần đây, làm đồ án với nhóm 5 người mà tổ chức sân chơi đợt hè. Phải nói là nhóm mình rất hợp nhau, một bạn đã đồng lòng là cả nhóm liền đồng lòng, đề tài đã chọn thì khó, không làm theo lịch, không phân chia cụ thể ai làm này, làm kia, vào thời gian nào là ngợp và dễ bỏ ngay. May mắn thay, từ đầu năm 2021 đến lúc này, mình đã học được rất nhiều thứ liên quan đến phát triển năng lực cá nhân, làm việc nhóm như thế nào. Kiến thức từ đợt làm Vis For Teacher và đợt Problem Based Learning lại có thể vận dụng ngay luôn, thế là cả nhóm hoàn thành xong 2 đồ án với thời gian là một tháng rưỡi, không lệch một tí thời gian nào, và kết quả thì đạt được sự kỳ vọng của nhóm. Khâm phục các bạn mình thật, tính mình khó chịu thế mà vẫn có thể hợp tác được. Đặc biệt, đợi này cả nhóm học được cả mớ kiến thức, phải nói là rất nhiều 🥳Mong rằng, năm 2022, mình và mọi người cũng sẽ có những cơ hội học tập tuyệt vời như thế 😁" }, { "title": "Markov Chain và bài toán &#39;Sáng nay ăn gì&#39;", "url": "/posts/markov-chain-va-bai-toan-sang-nay-an-gi/", "categories": "knowledge", "tags": "machine learning, probability, markov chain, markov process", "date": "2021-12-26 21:35:00 +0700", "snippet": "Nội dung 1. Định nghĩa Markov chain 2. Bài toán “sáng nay ăn gì” 3. Tổng kếtTrong bài viết này, chúng ta sẽ đi qua sơ lược về định nghĩa của Markov chain, từ đó hiểu thêm về Markov chain để ứng dụng vào một bài toán và thực nghiệm bằng Python.1. Định nghĩa Markov chainMarkov chain (chuỗi Markov), được đặt theo tên nhà toán học người Nga Andrey Markov, là một mô hình ngẫu nhiên hay tiến trình ngẫu nhiên mô tả một chuỗi các sự kiện có khả năng xảy ra, mà xác suất để xảy ra sự kiện tiếp theo phụ thuộc chỉ vào sự kiện hiện tại. Đây là một mô hình “không có trí nhớ” (memorylessness), nghĩa là các sự kiện xảy ra trong quá khứ sẽ không được ghi nhớ, sự kiện trong tương lai chỉ phụ thuộc sự kiện hiện tại của mô hình.Markov chain là sự kết hợp bởi 2 thành phần: tập trạng thái $Q$ và ma trận chuyển đổi giữa các trạng thái $P$ (ma trận này sẽ là ma trận vuông).Ví dụ, ta định nghĩa Markov chain $\\text{MC}$ có: Tập trạng thái là $Q = { Q_1, Q_2, Q_3 }$ Ma trận chuyển đổi giứa các trạng thái là $\\begin{aligned} P = \\begin{bmatrix} P_{11} &amp;amp; P_{12} &amp;amp; P_{13} \\newline P_{21} &amp;amp; P_{22} &amp;amp; P_{23} \\newline P_{31} &amp;amp; P_{32} &amp;amp; P_{33} \\end{bmatrix}\\end{aligned}$Markov chain $\\text{MC}$ sẽ có hình dạng trông giống như một đồ thị có hướng, có trọng số, với các node trên đồ thị là các trạng thái trong tập trạng thái của Markov chain, và các trọng số trên các cạnh của đồ thị mô tả xác suất chuyển $P_{ij}$, là xác suất để di chuyển từ trạng thái $Q_i$ đến trạng thái $Q_j$. Nếu $P_{ij} = 0$, ta ngầm hiểu rằng không thể di chuyển giữa hai trạng thái $Q_i$ và $Q_j$. ⚠️ Lưu ý là các trạng thái cũng có thể quay trở về chính nó, ví dụ $P_{33}$ là xác suất để thời điểm hiện tại, Markov chain đang ở trạng thái $Q_3$ và thời điểm tiếp theo sẽ quay trở lại $Q_3$. Hình dưới đây mô tả Markov chain $\\text{MC}$.Để quan sát được đường đi của các trạng thái trong Markov chain, ta cần định nghĩa quan sát $X = (X_1, X_2, \\cdots, X_t, \\cdots, X_T)$ là một vector có $T$ thành phần, mô tả các quan sát của Markov chain theo thời gian, $X_t \\in Q$. $X=(X_1 = Q_1, X_2 = Q_1, X_3 = Q_2, X_4 = Q_3)$ là một ví dụ về chuỗi quan sát các trạng thái của Markov chain, với xác suất xảy ra chuỗi quan sát này là tích các xác suất chuyển đổi, $P(X) = \\prod_{i=1}^{T-1} X_{i}X_{i+1}$, trong ví dụ của chúng ta thì sẽ là $P(X) = P_{11}P_{12}P_{23}$, trên thực tế, ta có thể lấy logarit của $P(X)$, tạo thuận lợi cho việc tính toán, tránh bị tràn số trong các chương trình máy tính.Cụ thể hơn về ký hiệu toán học của xác suất chuyển đổi, $P_{ij}=Pr(X_{t+1} = Q_j|X_t = Q_i)$ là xác suất để thời điểm $t$, trạng thái hiện tại của Markov chain là $Q_i$, và trạng thái của quan sát trong tương lai $t+1$ là $Q_{j}$.2. Bài toán “Sáng nay ăn gì”Giả sử vào một buổi sáng nọ, bạn thức dậy với 2 lần reo chuông báo thức đã qua từ điện thoại, bạn ngồi dậy, với cái bụng đang reo lên, bạn liền suy nghĩ đến việc: sáng hôm nay mình sẽ ăn gì?. Sau khi ra đầu ngõ, bạn đứng trước “ngã tư”: quán phở cô Ba, xe bánh mì cô Hai, cơm tấm chú Sáu và xe súp cua của ông Bảy. Tuy rằng, bạn đã ăn sáng mấy chục năm cuộc đời rồi, nhưng việc lựa chọn món ăn chưa bao giờ là dễ cả. May mắn thay, trong một năm vừa qua, món ăn sáng của mỗi ngày đều đã được bạn lưu trữ trên điện thoại, trong ứng dụng ghi chú (đây chính là data quý giá). Sau khi đọc định nghĩa về Markov chain ở trên, bạn quyết định áp dụng để giải quyết bài toán “sáng nay ăn gì” này.Đó chỉ là một câu chuyện vui do tôi bịa ra để dẫn vào bài toán có thể giải quyết bằng Markov chain này. Trên thực tế, Markov chain có thể giải các bài toán to lớn hơn, nhưng trước tiên chúng ta cứ giải bài toán kia để bạn có thể lấp đầy cái bụng đã.Trong ví dụ này, tôi sẽ hiện thực bằng Python, đọc data theo thời gian lên và tìm bộ các trạng thái $Q$, rồi tìm xác suất của ma trận $P$ kia, sau đó chọn ngẫu nhiên trạng thái (món ăn sáng) tiếp theo trên phân phối đã biết của xác suất của trạng thái (món ăn) hiện tại. Bạn có thể tải data ở đâyĐối với bộ data ở trên, tập trạng thái của chúng ta sẽ là $Q={\\text{Phở}, \\text{Cơm tấm}, \\text{Bánh mì}, \\text{Súp cua}}$Trước tiên ta sẽ phải import các thư viện cần thiết vào Pythonimport numpy as np # tính toán trên ma trậnimport pandas as pd # đọc dữ liệu từ file csvfrom pprint import pprint # dùng cho mục đích in &quot;đẹp&quot;from collections import defaultdict # để đếm số lượng lần xảy ra của các trạng thái (đơn lẻ và cặp)Đọc dữ liệu và chuyển thành dạng list trong Python để dễ dàng sử dụngdf = pd.read_csv(&#39;breakfast.csv&#39;)data = df.Food.tolist()data[-5:] # xuất ra 5 món ăn cuối cùng bạn ăn[&#39;Phở&#39;, &#39;Cơm tấm&#39;, &#39;Bánh mì&#39;, &#39;Phở&#39;, &#39;Phở&#39;]Để có thể tạo ma trận P, trước tiên ta phải đếm các cặp và các giá trị đơn lẻ trước, sau đó đi chuẩn hóa# tạo nơi lưu trữ giá trịfood_count = defaultdict(int)food_pair_count = defaultdict(lambda: defaultdict(float))Đếm các giá trị# food_count: đếm số lần xuất hiện của một trạng thái# food_pair_count: đếm tất cả các cặp trạng thái có thể [current][future]n = len(data)for i in range(n): food_count[data[i]] += 1 if i == n - 1: # self loop food_pair_count[data[i]][data[i]] += 1 break food_pair_count[data[i]][data[i + 1]] += 1Chuẩn hóa theo tổng hàng# chuẩn hóa theo tổng hàngfor key, value in food_pair_count.items(): for k, v in value.items(): food_pair_count[key][k] /= food_count[key] # chuẩn hóaDo ma trận không giống như dictionary trong Python, ta chỉ có thể truy cập được bằng chỉ mục (index) của trạng thái, vì vậy ta cần phải có một dictionary lưu trữ các index của các trạng thái# lấy index của các món ăn để dễ thao táckeys = list(food_count.keys())idx = range(len(keys))key_to_idx = dict(zip(keys, idx)) # key to indexprint(key_to_idx){&#39;Bánh mì&#39;: 0, &#39;Cơm tấm&#39;: 1, &#39;Phở&#39;: 2, &#39;Súp cua&#39;: 3}Ta bây giờ có thể tạo ma trận $P$ từ xác suất đã chuẩn hóa từ bước trên, và nên chuyển từ list sang numpy để tiện lợi cho việc tính toán hơn, do numpy là một thư viện rất mạnh của Python trong việc xử lý các thao tác liên quan đến đại số tuyến tính.P = []for key, value in food_pair_count.items(): P.append(list(value.values())) # chuyển list sang numpy để dễ tính toánP = np.array(P)print(&#39;Ma trận chuyển trạng thái P: &#39;)pprint(P)Ma trận chuyển trạng thái P: array([[0.26582278, 0.26582278, 0.26582278, 0.20253165], [0.25274725, 0.20879121, 0.24175824, 0.2967033 ], [0.28571429, 0.25274725, 0.28571429, 0.17582418], [0.25961538, 0.33653846, 0.21153846, 0.19230769]])Ta có thể kiểm tra tổng hàng xem có bằng $1$ hay chưa, nếu chưa có thể do lỗi ở các bước trước.# tổng hàng của ma trận phải luôn bằng 1print(P.sum(axis=1))[1. 1. 1. 1.] # tất cả đều 1, chuẩn Bây giờ, phần cuối sẽ đi dự đoán món ăn. Việc dự đoán món ăn (trạng thái) tương lai khá đơn giản, ta có thể hình dung thế này: đứng ở node của trạng thái hiện tại (món ăn cuối cùng của tập dữ liệu - món ăn hôm trước), có một tập các giá trị xác suất tương ứng với trọng số của các cạnh để đi đến node khác, chọn ngẫu nhiên một node để đi đến từ tập xác suất đó (một phân phối), và ta có thể chọn ngẫu nhiên theo phân phối với hàm numpy.random.choice.# dự đoán món ăn curr_food = data[-1]curr_distribution = P[key_to_idx[curr_food]]predicted_food = np.random.choice(keys, p=curr_distribution) # random walk with known distributionpredicted_probability = P[key_to_idx[curr_food]][key_to_idx[predicted_food]]In ra kết quả dự đoánprint(f&#39;Món ăn chúng ta ăn hôm trước: {data[-1]}&#39;)print(f&#39;Món ăn nên ăn vào hôm nay là &quot;{predicted_food}&quot;\\ với khả năng xảy ra là {round(predicted_probability * 100, 2)}%&#39;)Món ăn chúng ta ăn hôm trước: PhởMón ăn nên ăn vào hôm nay là &quot;Bánh mì&quot; với khả năng xảy ra là 28.57%Vậy mô hình Markov chain chúng ta đã hiện thực đã dự đoán cho chúng ta món “Bánh mì” vào hôm nay.⚠️ Lưu ý: Các giá trị, số liệu được xuất ra trong bài có thể khác, tùy thuộc vào dữ liệu cung cấp và sự lựa chọn ngẫu nhiên của các hàm trên.Chi tiết toàn bộ code, bạn đọc có thể tham khảo ở đây3. Tổng kếtTrên đây chỉ là một ví dụ nhỏ để mô tả khả năng của Markov chain. Ta có thể bắt gặp Markov chain trong nhiều bài toán khác như xây dựng mô hình ngôn ngữ n-gram trong lĩnh vực Xử lý ngôn ngữ tự nhiên, có thể ứng dụng vào việc Xếp hạng trang (PageRank) của Google (nhưng trên thực tế, Google sử dụng các mô hình phức tạp hơn Markov chain). Markov chain có thể phát triển lên một dạng khác, mô hình Markov ẩn, mà có thể ứng dụng trong bài toán Nhận dạng giọng nói. Và rất nhiều các ứng dụng khác trong các lĩnh vực Vật lý, Hóa học, Sinh học, Lý thuyết hàng đợi, … Bạn đọc có thể đọc thêm ở đường link này." }, { "title": "Nguồn tài liệu để học NLP", "url": "/posts/source-nlp/", "categories": "resource, share", "tags": "machine learning, nlp, ctc, rnn", "date": "2021-12-23 15:11:00 +0700", "snippet": "Bài viết này mang tính chất lưu trữ và chia sẻ.Những nguồn khi mới bắt đầu How to get started in nlp - mediumDữ liệu nlp-datasets - githubSách Deep Learning for NLP and Speech Recognition: mọi người lên zlib rồi gõ tên này là sách sẽ ra, bản pdf mới coong. Cuốn này sẽ tập trung vào cả NLP và Speech Recognition, đi từ các kiến thức nền tảng của Machine Learning, sau đó đến Deep Learning và các lý thuyết, kỹ thuật được dùng cho cả NLP và Speech Recognition. Cuốn sách này còn được hiện thực bằng Pytorch, Tensorflow nên đọc xong tha hồ mà lên tay gõ phím.Cụ thể chủ đềRecurrent Neural Network Understanding LSTM: https://colah.github.io/posts/2015-08-Understanding-LSTMs The Unreasonable Effectiveness of Recurrent Neural Networks: http://karpathy.github.io/2015/05/21/rnn-effectiveness/ Attention and Augmented Recurrent Neural Networks: https://distill.pub/2016/augmented-rnns/ Connectionist Temporal Classifications S18 Recitation 6: CTC: https://youtu.be/e0ia-mN-7Kk Sequence modeling with CTC: https://distill.pub/2017/ctc/ An Intuitive Explanation of Connectionist Temporal Classification: https://towardsdatascience.com/intuitively-understanding-connectionist-temporal-classification-3797e43a86c Các blog machine Andrej Karpathy blog: https://karpathy.github.io" } ]
